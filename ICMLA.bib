@article{rao2017impact,
  title={The impact of administrative burden on academic physicians: results of a hospital-wide physician survey},
  author={Rao, Sandhya K and Kimball, Alexa B and Lehrhoff, Sara R and Hidrue, Michael K and Colton, Deborah G and Ferris, Timothy G and Torchiana, David F},
  journal={Academic Medicine},
  volume={92},
  number={2},
  pages={237--243},
  year={2017},
  publisher={LWW}
}




@misc{HHS2019str,
title = {Strategy on Reducing Regulatory and Administrative Burden Relating to the Use Of Health \uppercase{IT} and \uppercase{EHR}s},
author="{HHS,  Office of the National Coordinator for Health Information Technology}",
 howpublished = "\url{https://www.healthit.gov/sites/default/files/page/2018-11/Draft%20Strategy%20on%20Reducing%20Regulatory%20and%20Administrative%20Burden%20Relating.pdf}",
year = 2020,
note         = "Accessed: 2020-7-28"}
% PROBLEM IT AND EHRs not capitalize.  url not displayed

@article{cutler2012reducing,
  title={Reducing administrative costs and improving the health care system},
  author={Cutler, David M and Wikler, Elizabeth and Basch, Peter},
  journal={New England Journal of Medicine},
  year={2012},
  publisher={New England Journal of Medicine (NEJM/MMS)}
}

@misc{lesidea1,
      title        = "Strategy on Reducing Regulatory and
Administrative Burden Relating to the Use
of Health IT and EHRs",
      author       = "{NASA}",
      howpublished = "\url{https://www.healthit.gov/sites/default/files/page/2018-11/Draft%20Strategy%20on%20Reducing%20Regulatory%20and%20Administrative%20Burden%20Relating.pdf}",
      year         = 2019,
      note         = "Accessed: 2020-7-26"
    }

@article{vostok2013assessment,
  title={Assessment of the burden of mandatory reporting of health care-associated infection using the National Healthcare Safety Network in Massachusetts},
  author={Vostok, Johanna and Lapsley, William and McElroy, Nora and Onofrey, Shauna and McHale, Eileen and Johnson, Nicole and DeMaria, Alfred},
  journal={American journal of infection control},
  volume={41},
  number={5},
  pages={466--468},
  year={2013},
  publisher={Elsevier}
}

@article{paffenroth2018robust,
  title={Robust pca for anomaly detection in cyber networks},
  author={Paffenroth, Randy and Kay, Kathleen and Servi, Les},
  journal={arXiv preprint arXiv:1801.01571},
  year={2018}
}

@inproceedings{Donoho2003,
author = {Donoho, D and Grimes, C},
booktitle = {Proceedings of National Academy of Science},
pages = {5591--5596},
title = {{Hessian eigenmaps: new tools for nonlinear dimensionality reduction}},
volume = {100},
year = {2003}
}
@inproceedings{paffenroth2011a,
author = {Paffenroth, R and Toit, P Du and Scharf, L and Jayasumana, A},
booktitle = {2011 Joint Meeting of the Military Sensing Symposia (MSS) Specialty Groups},
title = {{Space-Time Signal Processing for Detecting and Classifying Distributed Attacks in Networks}},
year = {2011}
}
@article{Miller2010,
author = {Miller, B and Bliss, N and Wolfe, PJ},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller, Bliss, Wolfe - 2010 - Subgraph detection using eigenvector L1 norms.pdf:pdf},
journal = {Advances in Neural {\ldots}},
pages = {1--9},
title = {{Subgraph detection using eigenvector L1 norms}},
url = {http://machinelearning.wustl.edu/mlpapers/paper{\_}files/NIPS2010{\_}0954.pdf},
year = {2010}
}
@article{Hu2013,
abstract = {Recovering a large matrix from a small subset of its entries is a challenging problem arising in many real applications, such as image inpainting and recommender systems. Many existing approaches formulate this problem as a general low-rank matrix approximation problem. Since the rank operator is nonconvex and discontinuous, most of the recent theoretical studies use the nuclear norm as a convex relaxation. One major limitation of the existing approaches based on nuclear norm minimization is that all the singular values are simultaneously minimized, and thus the rank may not be well approximated in practice. In this paper, we propose to achieve a better approximation to the rank of matrix by truncated nuclear norm, which is given by the nuclear norm subtracted by the sum of the largest few singular values. In addition, we develop a novel matrix completion algorithm by minimizing the Truncated Nuclear Norm. We further develop three efficient iterative procedures, TNNR-ADMM, TNNR-APGL, and TNNR-ADMMAP, to solve the optimization problem. TNNR-ADMM utilizes the alternating direction method of multipliers (ADMM), while TNNR-AGPL applies the accelerated proximal gradient line search method (APGL) for the final optimization. For TNNR-ADMMAP, we make use of an adaptive penalty according to a novel update rule for ADMM to achieve a faster convergence rate. Our empirical study shows encouraging results of the proposed algorithms in comparison to the state-of-the-art matrix completion algorithms on both synthetic and real visual datasets.},
author = {Hu, Yao and Zhang, Debing and Ye, Jieping and Li, Xuelong and He, Xiaofei},
doi = {10.1109/TPAMI.2012.271},
issn = {1939-3539},
journal = {IEEE transactions on pattern analysis and machine intelligence},
pages = {2117--30},
pmid = {23868774},
title = {{Fast and Accurate Matrix Completion via Truncated Nuclear Norm Regularization.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23868774},
volume = {35},
year = {2013}
}
@article{Shimodaira2004,
author = {Shimodaira, H},
journal = {The Annals of Statistics},
title = {{Approximately unbiased tests of regions using multistep-multiscale bootstrap resampling}},
url = {http://projecteuclid.org/euclid.aos/1107794881},
year = {2004}
}
@article{SzczerbaRoutePlan2000,
author = {Szczerba, R J and Galkowski, P and Glickstein, I S and Ternullo, N},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
month = {jul},
number = {3},
pages = {869--878},
title = {{A Robust Algorithm for Real-Time Route Planning}},
volume = {36},
year = {2000}
}
@book{Mitchell1997,
abstract = {This book covers the field of machine learning, which is the study of algorithms that allow computer programs to automatically improve through experience. The book is intended to support upper level undergraduate and introductory level graduate courses in machine learning.},
author = {Mitchell, Tom M},
booktitle = {Annual Review Of Computer Science},
doi = {10.1145/242224.242229},
isbn = {0070428077},
issn = {87567016},
pages = {417--433},
pmid = {20236947},
title = {{Machine Learning}},
url = {http://www.amazon.ca/exec/obidos/redirect?tag=citeulike09-20{\&}path=ASIN/0070428077},
volume = {4},
year = {1997}
}
@article{Ramasubramanian2009,
author = {Ramasubramanian, Venugopalan and Malkhi, Dahlia and Kuhn, Fabian},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ramasubramanian, Malkhi, Kuhn - 2009 - On the Treeness of Internet Latency and Bandwidth.pdf:pdf},
isbn = {9781605585116},
journal = {Network},
keywords = {bandwidth,internet topology,latency,sequoia,tree embedding},
title = {{On the Treeness of Internet Latency and Bandwidth}},
year = {2009}
}
@book{20,
abstract = {This monograph is an intertwined tale of eigenvalues and their use in unlocking a thousand secrets about graphs. The stories will be told how the spectrum reveals fundamental properties of a graph, how spectral graph theory links the discrete universe to the continuous one through geometric, analytic and algebraic techniques, and how, through eigenvalues, theory and applications in communications and computer science come together in symbiotic harmony....},
author = {Chung, F R K},
booktitle = {ACM SIGACT News},
doi = {10.1145/568547.568553},
isbn = {0821803158},
issn = {01635700},
pages = {14},
publisher = {American Mathematical Society},
title = {{Spectral Graph Theory}},
url = {http://www.ams.org/bookstore-getitem/item=cbms-92},
volume = {30},
year = {1997}
}
@article{Weinberger2006,
abstract = {Abstract Can we detect low dimensional structure in high dimensional data sets of images? In this paper, we propose an algorithm for unsupervised learning of image manifolds by semidefinite programming. Given a data set of images, our algorithm computes a low dimensional representation of each image with the property that distances between nearby images are preserved. More generally, it can be used to analyze high dimensional data that lies on or near a low dimensional manifold. We illustrate the algorithm on easily visualized examples of curves and surfaces, as well as on actual images of faces, handwritten digits, and solid objects.},
author = {Weinberger, KQ Kilian Q and Saul, Lawrence K LK},
doi = {10.1007/s11263-005-4939-z},
isbn = {0769521584},
issn = {09205691},
journal = {International Journal of Computer Vision},
number = {1},
pages = {77--90},
publisher = {Springer Netherlands},
title = {{Unsupervised Learning of Image Manifolds by Semidefinite Programming}},
url = {http://www.springerlink.com/index/10.1007/s11263-005-4939-z http://link.springer.com/article/10.1007/s11263-005-4939-z},
volume = {70},
year = {2006}
}
@article{Parikh2013,
author = {Parikh, N and Boyd, S},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Parikh, Boyd - 2013 - Proximal algorithms.pdf:pdf},
journal = {Foundations and Trends in Optimization},
title = {{Proximal algorithms}},
url = {http://www.stanford.edu/{~}boyd/papers/pdf/prox{\_}algs.pdf},
year = {2013}
}
@article{Ganesh,
author = {Ganesh, Arvind and Wright, John and Li, Xiaodong},
journal = {(ISIT), 2010 IEEE},
title = {{Dense error correction for low-rank matrices via principal component pursuit}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5513538},
year = {2010}
}
@article{Asimow1978,
abstract = {We regard a graph G as a set {\{}1,{\ldots}, v{\}} together with a nonempty set E of two-element subsets of {\{}1,{\ldots}, v{\}}. Let p = (p1,{\ldots}, pv) be an element of Rnv representing v points in Rn and consider the realization G(p) of G in Rn consisting of the line segments [pi, pj] in Rn for {\{}i, j{\}} ϵ E. The figure G(p) is said to be rigid in Rn if every continuous path in Rnv, beginning at p and preserving the edge lengths of G(p), terminates at a point q ϵ Rnv which is the image (Tp1,{\ldots}, Tpv) of p under an isometry T of Rn. We here study the rigidity and infinitesimal rigidity of graphs, surfaces, and more general structures. A graph theoretic method for determining the rigidity of graphs in R2 is discussed, followed by an examination of the rigidity of convex polyhedral surfaces in R3.},
author = {Asimow, L. and Roth, B.},
doi = {10.1090/S0002-9947-1978-0511410-9},
issn = {0002-9947},
journal = {Transactions of the American Mathematical Society},
pages = {279--279},
title = {{The rigidity of graphs}},
url = {http://www.ams.org/tran/1978-245-00/S0002-9947-1978-0511410-9/},
volume = {245},
year = {1978}
}
@article{He2011,
abstract = {Principal component analysis (PCA) minimizes the mean square error (MSE) and is sensitive to outliers. In this paper, we present a new rotational-invariant PCA based on maximum correntropy criterion (MCC). A half-quadratic optimization algorithm is adopted to compute the correntropy objective. At each iteration, the complex optimization problem is reduced to a quadratic problem that can be efficiently solved by a standard optimization method. The proposed method exhibits the following benefits: 1) it is robust to outliers through the mechanism of MCC which can be more theoretically solid than a heuristic rule based on MSE; 2) it requires no assumption about the zero-mean of data for processing and can estimate data mean during optimization; and 3) its optimal solution consists of principal eigenvectors of a robust covariance matrix corresponding to the largest eigenvalues. In addition, kernel techniques are further introduced in the proposed method to deal with nonlinearly distributed data. Numerical results demonstrate that the proposed method can outperform robust rotational-invariant PCAs based on L(1) norm when outliers occur.},
author = {He, Ran and Hu, Bao-Gang and Zheng, Wei-Shi and Kong, Xiang-Wei},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2011 - Robust principal component analysis based on maximum correntropy criterion.pdf:pdf},
institution = {National Laboratory of Pattern Recognition, Institute of Automation Chinese Academy of Sciences, Beijing 100190, China. rhe@nlpr.ia.ac.cn},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
number = {6},
pages = {1485--1494},
pmid = {21216713},
publisher = {IEEE},
title = {{Robust principal component analysis based on maximum correntropy criterion.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21216713},
volume = {20},
year = {2011}
}
@article{Lakhina2004a,
abstract = {Anomalies are unusual and significant changes in a network's traffic levels, which can often span multiple links. Diagnosing anomalies is critical for both network operators and end users. It is a difficult problem because one must extract and interpret anomalous patterns from large amounts of high-dimensional, noisy data.In this paper we propose a general method to diagnose anomalies. This method is based on a separation of the high-dimensional space occupied by a set of network traffic measurements into disjoint subspaces corresponding to normal and anomalous network conditions. We show that this separation can be performed effectively by Principal Component Analysis.Using only simple traffic measurements from links, we study volume anomalies and show that the method can: (1) accurately detect when a volume anomaly is occurring; (2) correctly identify the underlying origin-destination (OD) flow which is the source of the anomaly; and (3) accurately estimate the amount of traffic involved in the anomalous OD flow.We evaluate the method's ability to diagnose (i.e., detect, identify, and quantify) both existing and synthetically injected volume anomalies in real traffic from two backbone networks. Our method consistently diagnoses the largest volume anomalies, and does so with a very low false alarm rate.},
author = {Lakhina, Anukool and Crovella, Mark and Diot, Christophe},
doi = {10.1145/1030194.1015492},
isbn = {1581138628},
issn = {01464833},
journal = {ACM SIGCOMM Computer Communication Review},
keywords = {anomaly detection,network traffic analysis},
number = {4},
pages = {219},
pmid = {9689626},
title = {{Diagnosing network-wide traffic anomalies}},
url = {http://dl.acm.org/citation.cfm?id=1030194.1015492},
volume = {34},
year = {2004}
}
@article{candes06st,
author = {Cand{\`{e}}s, E and Romberg, J and Tao, T},
journal = {Comm. on Pure and Applied Math.},
number = {8},
pages = {1207--1223},
title = {{Stable signal recovery from incomplete and inaccurate measurements}},
volume = {59},
year = {2006}
}
@article{Sanders2011,
abstract = {It's easy enough to install Wireshark and begin capturing packets off the wire-or from the air. But how do you interpret those packets once you've captured them? And how can those packets help you to better understand what's going on under the hood of your network? "Practical Packet Analysis" shows how to use Wireshark to capture and then analyze packets as you take an indepth look at real-world packet analysis and network troubleshooting. The way the pros do it. Wireshark (derived from the Ethereal project), has become the world's most popular network sniffing application. But while Wireshark comes with documentation, there's not a whole lot of information to show you how to use it in real-world scenarios. "Practical Packet Analysis" shows you how to: Use packet analysis to tackle common network problems, such as loss of connectivity, slow networks, malware infections, and more Build customized capture and display filters Tap into live network communication Graph traffic patterns to visualize the data flowing across your network Use advanced Wireshark features to understand confusing packets Build statistics and reports to help you better explain technical network information to non-technical users Because net-centric computing requires a deep understanding of network communication at the packet level, "Practical Packet Analysis" is a must have for any network technician, administrator, or engineer troubleshooting network problems of any kind.},
author = {Sanders, Chris},
doi = {10.1016/S1353-4858(11)70082-4},
isbn = {9781593272661},
issn = {13534858},
journal = {Network Security},
number = {8},
pages = {4},
title = {{Practical Packet Analysis: using Wireshark to solve real-world network problems}},
url = {http://www.sciencedirect.com/science/article/pii/S1353485811700824},
volume = {2011},
year = {2011}
}
@article{chartrand2003theory,
author = {Chartrand, Gary and Zhang, Ping},
journal = {Congressus Numerantium},
pages = {47--68},
publisher = {Winnipeg; Utilitas Mathematica; 1998},
title = {{The theory and applications of resolvability in graphs}},
year = {2003}
}
@article{Toh2010,
author = {Toh, KC and Yun, S},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Toh, Yun - 2010 - An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems.pdf:pdf},
journal = {Pacific Journal of Optimization},
title = {{An accelerated proximal gradient algorithm for nuclear norm regularized linear least squares problems}},
url = {http://www.math.nus.edu.sg/{~}mattohkc/papers/mc11.pdf},
year = {2010}
}
@inproceedings{Bandara2010a,
address = {Denver, CO},
author = {Bandara, V. and Pezeshki, A. and Jayasumana, A. P.},
booktitle = {Proc. 35th Conference on Local Computer Networks},
title = {{Modeling Spatial and Temporal Behavior of internet Traffic Anomalies}},
year = {2010}
}
@incollection{Smith1997,
abstract = {The time and frequency domains are alternative ways of representing signals. The Fourier transform is the mathematical relationship between these two representations. If a signal is modified in one domain, it will also be changed in the other domain, although usually not in the same way. For example, it was shown in the last chapter that convolving time domain signals results in their frequency spectra being multiplied. Other mathematical operations, such as addition, scaling and shifting, also have a matching operation in the opposite domain. These relationships are called properties of the Fourier Transform, how a mathematical change in one domain results in a mathematical change in the other domain.},
author = {Smith, Steven W.},
booktitle = {The Scientist and Engineer's Guide to Digital Signal Processing},
doi = {10.1016/B978-0-7506-7444-7/50047-9},
isbn = {9780750674447},
pages = {185--208},
title = {{Fourier Transform Properties}},
year = {1997}
}
@inproceedings{PafNovDan07,
author = {Paffenroth, R and Novoselov, R and Danford, S and Teixeira, M and Chan, S and Poore, A},
booktitle = {Proceedings of the SPIE, Conference on Signal and Data Processing of Small Targets},
editor = {Drummond, O E},
pages = {66990Q},
title = {{Mitigation of biases using the Schmidt-Kalman filter}},
volume = {6969},
year = {2007}
}
@misc{predict,
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - PREDICT - Home.html:html},
howpublished = {https://www.predict.org/},
keywords = {DNN,DotNetNuke},
title = {{PREDICT - Home}},
url = {https://www.predict.org/},
urldate = {2013-06-24}
}
@article{Calderon2013,
abstract = {Single-particle tracking (SPT) has been extensively used to obtain information about diffusion and directed motion in a wide range of biological applications. Recently, new methods have appeared for obtaining precise (10s of nm) spatial information in three dimensions (3D) with high temporal resolution (measurements obtained every 4 ms), which promise to more accurately sense the true dynamical behavior in the natural 3D cellular environment. Despite the quantitative 3D tracking information, the range of mathematical methods for extracting information about the underlying system has been limited mostly to mean-squared displacement analysis and other techniques not accounting for complex 3D kinetic interactions. There is a great need for new analysis tools aiming to more fully extract the biological information content from in vivo SPT measurements. High-resolution SPT experimental data has enormous potential to objectively scrutinize various proposed mechanistic schemes arising from theoretical biophysics and cell biology. At the same time, methods for rigorously checking the statistical consistency of both model assumptions and estimated parameters against observed experimental data (i.e., goodness-of-fit tests) have not received great attention. We demonstrate methods enabling (1) estimation of the parameters of 3D stochastic differential equation (SDE) models of the underlying dynamics given only one trajectory; and (2) construction of hypothesis tests checking the consistency of the fitted model with the observed trajectory so that extracted parameters are not overinterpreted (the tools are applicable to linear or nonlinear SDEs calibrated from nonstationary time series data). The approach is demonstrated on high-resolution 3D trajectories of single ARG3 mRNA particles in yeast cells in order to show the power of the methods in detecting signatures of transient directed transport. The methods presented are generally relevant to a wide variety of 2D and 3D SPT tracking applications.},
author = {Calderon, CP and Thompson, MA},
doi = {10.1021/jp4064214},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Calderon, Thompson - 2013 - Quantifying Transient 3D Dynamical Phenomena of Single mRNA Particles in Live Yeast Cell Measurements.pdf:pdf},
issn = {1520-5207},
journal = {The Journal of Physical Chemistry B},
keywords = {Messenger,Messenger: chemistry,Messenger: metabolism,Models,Ornithine Carbamoyltransferase,Ornithine Carbamoyltransferase: genetics,Ornithine Carbamoyltransferase: metabolism,RNA,Saccharomyces cerevisiae,Saccharomyces cerevisiae Proteins,Saccharomyces cerevisiae Proteins: genetics,Saccharomyces cerevisiae Proteins: metabolism,Saccharomyces cerevisiae: metabolism,Theoretical},
month = {dec},
number = {49},
pages = {15701--13},
pmid = {24015725},
publisher = {American Chemical Society},
title = {{Quantifying Transient 3D Dynamical Phenomena of Single mRNA Particles in Live Yeast Cell Measurements}},
url = {http://dx.doi.org/10.1021/jp4064214 http://pubs.acs.org/doi/abs/10.1021/jp4064214},
volume = {117},
year = {2013}
}
@article{htf01,
abstract = {During the past decade there has been an explosion in computation and information technology. With it has come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting-the first comprehensive treatment of this topic in any book. Trevor Hastie, Robert Tibshirani, and Jerome Friedman are professors of statistics at Stanford University. They are prominent researchers in this area: Hastie and Tibshirani developed generalized additive models and wrote a popular book of that title. Hastie wrote much of the statistical modeling software in S-PLUS and invented principal curves and surfaces. Tibshirani proposed the Lasso and is co-author of the very successful An Introduction to the Bootstrap. Friedman is the co-inventor of many data-mining tools including CART, MARS, and projection pursuit. FROM THE REVIEWS: TECHNOMETRICS "This is a vast and complex book. Generally, it concentrates on explaining why and how the methods work, rather than how to use them. Examples and especially the visualizations are principle features...As a source for the methods of statistical learning...it will probably be a long time before there is a competitor to this book."},
address = {Upper Saddle River, New Jersey 07458},
archivePrefix = {arXiv},
arxivId = {1010.3003},
author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
doi = {10.1007/b94608},
eprint = {1010.3003},
isbn = {9780387848570},
issn = {03436993},
journal = {Elements},
pages = {337--387},
pmid = {15512507},
publisher = {Springer},
title = {{The Elements of Statistical Learning}},
url = {http://www.springerlink.com/index/10.1007/b94608},
volume = {1},
year = {2009}
}
@article{RubEMD00,
address = {Hingham, MA, USA},
author = {Rubner, Yossi and Tomasi, Carlo and Guibas, Leonidas J},
doi = {http://dx.doi.org/10.1023/A:1026543900054},
issn = {0920-5691},
journal = {Int. J. Comput. Vision},
number = {2},
pages = {99--121},
publisher = {Kluwer Academic Publishers},
title = {{The Earth Mover's Distance as a Metric for Image Retrieval}},
volume = {40},
year = {2000}
}
@book{Chung1996,
author = {Chung, Fan R. K.},
isbn = {0821803158},
pages = {207},
publisher = {American Mathematical Society},
title = {{Spectral Graph Theory (CBMS Regional Conference Series in Mathematics, No. 92)}},
url = {http://www.amazon.com/Spectral-Theory-Regional-Conference-Mathematics/dp/0821803158},
year = {1996}
}
@article{Olding2009,
author = {Olding, BP and Wolfe, PJ},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Olding, Wolfe - 2009 - Inference for graphs and networks extending classical tools to modern data.pdf:pdf},
journal = {arXiv preprint arXiv:0906.4980},
keywords = {and phrases,approximate inference,hypothesis testing,network data analysis,random graphs,relational data,spectral},
title = {{Inference for graphs and networks: extending classical tools to modern data}},
url = {http://arxiv.org/abs/0906.4980},
year = {2009}
}
@article{Weinberger2006a,
abstract = {Many problems in AI are simplified by clever representations of sensory or symbolic input. How to discover such rep- resentations automatically, from large amounts of unlabeled data, remains a fundamental challenge. The goal of statis- tical methods for dimensionality reduction is to detect and discover low dimensional structure in high dimensional data. In this paper, we review a recently proposed algorithm— maximum variance unfolding—for learning faithful low di- mensional representations of high dimensional data. The algorithm relies on modern tools in convex optimization that are proving increasingly useful in many areas of ma- chine learning.},
author = {Weinberger, Kq and Saul, Lk},
isbn = {9781577352815},
issn = {01639374},
journal = {Aaai},
keywords = {new scientific and technical advances in research},
number = {2},
pages = {1683--1686},
publisher = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
title = {{An introduction to nonlinear dimensionality reduction by maximum variance unfolding}},
url = {http://www.aaai.org/Papers/AAAI/2006/AAAI06-280.pdf},
volume = {21},
year = {2006}
}
@misc{skaion,
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Skaion Corporation - Cyber Test SupportReal Traffic Generation.html:html},
howpublished = {http://www.skaion.com/},
title = {{Skaion Corporation - Cyber Test Support/Real Traffic Generation}},
url = {http://www.skaion.com/},
urldate = {2013-06-24}
}
@article{Halko2011,
author = {Halko, N and Martinsson, PG and Tropp, JA},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Halko, Martinsson, Tropp - 2011 - Finding Structure with Randomness Probabilistic Algorithms for Constructing Approximate Matrix Decompo.pdf:pdf},
journal = {SIAM review},
keywords = {dimension reduction,eigenvalue decomposition,factorization,interpolative decomposition,johnson,lindenstrauss lemma,matrix approximation,parallel algorithm,pass-efficient algorithm,principal component analysis,random matrix,randomized algorithm,rank-revealing qr,singular value decomposition,streaming algorithm},
number = {2},
pages = {217--288},
title = {{Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions}},
url = {http://epubs.siam.org/doi/abs/10.1137/090771806},
volume = {53},
year = {2011}
}
@article{chen99at,
author = {Chen, S S and Donoho, D L and Saunders, M A},
journal = {SIAM J. Sci. Comput.},
number = {1},
pages = {33--61},
title = {{Atomic decomposition by basis pursuit}},
volume = {20},
year = {1999}
}
@inproceedings{Comaniciu2002,
address = {Los Alamitos, CA, USA},
author = {Comaniciu, Dorin and Meer, Peter},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
issn = {0162-8828},
number = {5},
pages = {603--619},
publisher = {IEEE Computer Society},
title = {{Mean Shift: A Robust Approach Toward Feature Space Analysis}},
volume = {24},
year = {2002}
}
@book{Osborne2003,
author = {Osborne, Martin},
isbn = {0195128958},
publisher = {Oxford University Press, USA},
title = {{An Introduction to Game Theory}},
url = {http://www.citeulike.org/user/ze/article/606559},
year = {2003}
}
@misc{Chen1998,
abstract = {. The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries — stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), Matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis Pursuit (BP) is a principle for decomposing a signal into an “optimal ” superposition of dictionary elements, where optimal means having the smallest l 1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, in abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.},
author = {Chen, Scott Shaobing and Donoho, David L. and Michael and Saunders, A.},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 1998 - Atomic decomposition by basis pursuit.pdf:pdf},
pages = {33--61},
publisher = {SIAM Journal on Scientific Computing},
title = {{Atomic decomposition by basis pursuit}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.135.1907},
volume = {20},
year = {1998}
}
@inproceedings{Dahl,
author = {Dahl, Joachim and Vandenberghe, Lieven},
booktitle = {http://abel.ee.ucla.edu/cvxopt/index.html},
title = {{CVXOPT}},
url = {http://abel.ee.ucla.edu/cvxopt/index.html}
}
@article{Baraniuk2009,
author = {Baraniuk, RG and Wakin, MB},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Baraniuk, Wakin - 2009 - Random projections of smooth manifolds.pdf:pdf},
isbn = {0001406108},
journal = {Foundations of Computational Mathematics},
keywords = {53a07,57r40,62h99,65c99,68p30,68t05,94a12,94a29,ams subject classification,compressed sensing,dimensionality reduction,johnson-lindenstrauss lemma,manifold learning,manifolds,random projections,sity,spar-},
number = {October 2006},
pages = {1--23},
title = {{Random projections of smooth manifolds}},
url = {http://www.springerlink.com/index/5269N01302003958.pdf},
year = {2009}
}
@article{Singer2008,
author = {Singer, Amit and Coifman, Ronald R.},
doi = {10.1016/j.acha.2007.11.001},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Singer, Coifman - 2008 - Non-linear independent component analysis with diffusion maps.pdf:pdf},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
month = {sep},
number = {2},
pages = {226--239},
title = {{Non-linear independent component analysis with diffusion maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520307001285},
volume = {25},
year = {2008}
}
@article{Blasch2005,
author = {Blasch, E. and Plano, S.},
doi = {10.1109/ICIF.2005.1591828},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Blasch, Plano - 2005 - DFIG Level 5 (User Refinement) issues supporting Situational Assessment Reasoning.pdf:pdf},
isbn = {0-7803-9286-8},
journal = {2005 7th International Conference on Information Fusion},
keywords = {design,fusion,interface,knowledge representation,situational assessment,user refinement},
number = {July},
pages = {xxxv--xliii},
publisher = {Ieee},
title = {{DFIG Level 5 (User Refinement) issues supporting Situational Assessment Reasoning}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1591828},
volume = {5},
year = {2005}
}
@book{Boyd2004,
abstract = {We are developing a dual panel breast-dedicated PET system using LSO scintillators coupled to position sensitive avalanche photodiodes (PSAPD). The charge output is amplified and read using NOVA RENA-3 ASICs. This paper shows that the coincidence timing resolution of the RENA-3 ASIC can be improved using certain list-mode calibrations. We treat the calibration problem as a convex optimization problem and use the RENA-3s analog-based timing system to correct the measured data for time dispersion effects from correlated noise, PSAPD signal delays and varying signal amplitudes. The direct solution to the optimization problem involves a matrix inversion that grows order (n3) with the number of parameters. An iterative method using single-coordinate descent to approximate the inversion grows order (n). The inversion does not need to run to convergence, since any gains at high iteration number will be low compared to noise amplification. The system calibration method is demonstrated with measured pulser data as well as with two LSO-PSAPD detectors in electronic coincidence. After applying the algorithm, the 511keV photopeak paired coincidence time resolution from the LSO-PSAPD detectors under study improved by 57{\%}, from the raw value of 16.30.07 ns FWHM to 6.920.02 ns FWHM (11.520.05 ns to 4.890.02 ns for unpaired photons).},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Boyd, Stephen and Vandenberghe, Lieven},
booktitle = {Optimization Methods and Software},
doi = {10.1017/CBO9780511804441},
eprint = {1111.6189v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd, Vandenberghe - 2009 - Convex optimization.pdf:pdf},
isbn = {9780511804441},
issn = {10556788},
number = {3},
pages = {487--487},
pmid = {20876008},
publisher = {Cambridge university press},
title = {{Convex Optimization}},
volume = {25},
year = {2004}
}
@inproceedings{ChanPaf08a,
author = {Chan, Stephanie and Paffenroth, Randy C},
booktitle = {Proceedings of the SPIE, Conference on Signal and Data Processing of Small Targets},
doi = {10.1117/12.778022},
editor = {Drummond, O E},
issn = {0277786X},
keywords = {distributed tracking,filtering,multi-hypothesis tracking,out-of-sequence measurements},
pages = {69691H--69691H--12},
publisher = {Spie},
title = {{Out-of-sequence measurement updates for multi-hypothesis tracking algorithms}},
url = {http://link.aip.org/link/PSISDG/v6969/i1/p69691H/s1{\&}Agg=doi},
volume = {6969},
year = {2008}
}
@article{Aharon2006,
author = {Aharon, M and Elad, M and Bruckstein, A},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Aharon, Elad, Bruckstein - 2006 - K-SVD An algorithm for designing overcomplete dictionaries for sparse representation.pdf:pdf},
journal = {Signal Processing, IEEE {\ldots}},
title = {{K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1710377},
year = {2006}
}
@article{Bloch2009,
author = {Bloch, Francis and Dutta, Bhaskar},
doi = {10.1016/j.geb.2008.09.034},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bloch, Dutta - 2009 - Correlated equilibria, incomplete information and coalitional deviations☆.pdf:pdf},
issn = {08998256},
journal = {Games and Economic Behavior},
keywords = {bloch is at greqam,coalitions,correlated equilibrium,dutta gratefully acknowledges support,from esrc grant res-000-22-0341,games with positive externalities,information sharing,universite d},
month = {jul},
number = {2},
pages = {721--728},
title = {{Correlated equilibria, incomplete information and coalitional deviations☆}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0899825608001796},
volume = {66},
year = {2009}
}
@article{Diamond2014,
author = {Diamond, S and Chu, E and Boyd, S},
title = {{CVXPY: A Python-embedded modeling language for convex optimization, version 0.2}},
url = {http://scholar.google.com/scholar?q=CVXpy{\&}btnG={\&}hl=en{\&}as{\_}sdt=0,22{\#}0},
year = {2014}
}
@article{Banerjee2010,
abstract = {This paper illustrates the functionality of Wireshark as a sniffing tool in networks. This has been proven by an experimental setup which depicts the efficiency of detection of a malicious packet in any network. Testing has been achieved through experimentation on a real time network analyzed by Wireshark. Inferences have been made which clearly depict Wireshark's capabilities highlighting it as a strong candidate for future development into a robust intrusion detection system. This paper highlights the working of Wireshark as a network protocol analyzer and also accentuates its flexibility as an open source utility to allow developers to add possible functionalities of intrusion detection devices in it.},
author = {Banerjee, Usha and Vashishtha, Ashutosh and Saxena, Mukul},
doi = {10.5120/1092-1427},
issn = {09758887},
journal = {International Journal of Computer Applications},
keywords = {Data,Intrusion Detection,Sniffing,WireShark},
number = {7},
pages = {975--8887},
title = {{Evaluation of the Capabilities of WireShark as a tool for Intrusion Detection}},
volume = {6},
year = {2010}
}
@book{chapelle2006semi,
author = {Chapelle, Olivier and Sch{\"{o}}lkopf, Bernhard and Zien, Alexander and Others},
publisher = {MIT press Cambridge},
title = {{Semi-supervised learning}},
url = {http://www.acad.bg/ebook/ml/MITPress- SemiSupervised Learning.pdf},
volume = {2},
year = {2006}
}
@misc{maxmind,
author = {inc. Maxmind and inc. Maxmind},
title = {https://www.maxmind.com},
year = {2015}
}
@inproceedings{Paffenroth2012a,
author = {Paffenroth, RC and Toit, PC Du and Scharf, LL and Jayasumana, A. P. and Bandara, V. and Nong, Ryan},
booktitle = {Cyber Sensing},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paffenroth et al. - 2012 - Space-time signal processing for distributed pattern detection in sensor networks.pdf:pdf;:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Paffenroth et al. - 2012 - Distributed pattern detection in cyber networks.pdf:pdf},
title = {{Distributed pattern detection in cyber networks}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Distributed+pattern+detection+in+cyber+networks{\#}0 http://spie.org/x648.html?product{\_}id=919711},
volume = {8393},
year = {2012}
}
@article{Candes2009,
abstract = {On the heels of compressed sensing, a remarkable new field has very recently emerged. This field addresses a broad range of problems of significant practical interest, namely, the recovery of a data matrix from what appears to be incomplete, and perhaps even corrupted, information. In its simplest form, the problem is to recover a matrix from a small sample of its entries, and comes up in many areas of science and engineering including collaborative filtering, machine learning, control, remote sensing, and computer vision to name a few. This paper surveys the novel literature on matrix completion, which shows that under some suitable conditions, one can recover an unknown low-rank matrix from a nearly minimal set of entries by solving a simple convex optimization problem, namely, nuclear-norm minimization subject to data constraints. Further, this paper introduces novel results showing that matrix completion is provably accurate even when the few observed entries are corrupted with a small amount of noise. A typical result is that one can recover an unknown n x n matrix of low rank r from just about nr log 2 n noisy samples with an error which is proportional to the noise level. We present numerical results which complement our quantitative analysis and show that, in practice, nuclear norm minimization accurately fills in the many missing entries of large low-rank matrices from just a few noisy samples. Some analogies between matrix completion and compressed sensing are discussed throughout.},
author = {Candes, Emmanuel J and Plan, Yaniv},
journal = {Proceedings of the IEEE},
keywords = {com,duality optimization,low rank matrices,matrix completion,nuclear norm minimization,oracle inequalities,semidefinite programming},
number = {6},
pages = {11},
title = {{Matrix Completion With Noise}},
url = {http://arxiv.org/abs/0903.3131},
volume = {98},
year = {2009}
}
@misc{caida,
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - CAIDA The Cooperative Association for Internet Data Analysis.html:html},
howpublished = {http://www.caida.org/home/},
title = {{CAIDA: The Cooperative Association for Internet Data Analysis}},
url = {http://www.caida.org/home/},
urldate = {2013-06-24}
}
@inproceedings{Wright2009,
author = {Wright, John and Ganesh, Arvind and Rao, Shankar and Peng, Yigang and Ma, Yi},
booktitle = {Advances in Neural Information Processing Systems},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wright et al. - 2009 - Robust Principal Component Analysis Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization.pdf:pdf},
pages = {2080--2088},
title = {{Robust Principal Component Analysis: Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization}},
url = {http://papers.nips.cc/paper/3704-robust-principal-component-analysis-exact-recovery-of-corrupted-low-rank-matrices-via-convex-optimization},
year = {2009}
}
@inproceedings{YosPaf10,
annote = {From Duplicate 1 (Nonlinear estimation for arrays of chemical sensors - Yosinski, Jason; Paffenroth, Randy)

From Duplicate 1 ( 


Nonlinear estimation for arrays of chemical sensors


- Yosinski, J; Paffenroth, R )

},
author = {Yosinski, Jason and Paffenroth, Randy},
booktitle = {Proceedings of the SPIE, Conference on Signal and Data Processing of Small Targets},
doi = {10.1117/12.849589},
editor = {Drummond, O E},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yosinski, Paffenroth - 2010 - Nonlinear estimation for arrays of chemical sensors(2).pdf:pdf},
keywords = {chemical detection,electronic olfactation,maximum likelihood estimation,raman spectrograph},
title = {{Nonlinear estimation for arrays of chemical sensors}},
url = {http://link.aip.org/link/PSISDG/v7698/i1/p769809/s1{\&}Agg=doi},
volume = {7698},
year = {2010}
}
@misc{Abdi2010a,
abstract = {Principal component analysis (pca) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the pca model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. Pca can be generalized as correspondence analysis (ca) in order to handle qualitative variables and as multiple factor analysis (mfa) in order to handle heterogenous sets of variables. Mathematically, pca depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (svd) of rectangular matrices.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Abdi, Herv{\'{e}} and Williams, Lynne J.},
booktitle = {Wiley Interdisciplinary Reviews: Computational Statistics},
doi = {10.1002/wics.101},
eprint = {arXiv:1011.1669v3},
isbn = {1939-0068},
issn = {19395108},
number = {4},
pages = {433--459},
pmid = {20931840},
title = {{Principal component analysis}},
volume = {2},
year = {2010}
}
@article{Meinshausen2006,
author = {Meinshausen, Nicolai},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Meinshausen - 2006 - False discovery control for multiple tests of association under general dependence.pdf:pdf},
journal = {Scandinavian journal of statistics},
keywords = {false discovery control,false discovery proportion,false discovery rate,multiple testing,short title},
pages = {1--18},
title = {{False discovery control for multiple tests of association under general dependence}},
url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9469.2005.00488.x/full},
year = {2006}
}
@article{Benjamini2001,
author = {Benjamini, Y and Yekutieli, D},
issn = {0090-5364},
journal = {Annals of statistics},
number = {4},
pages = {1165--1188},
publisher = {JSTOR},
title = {{THE CONTROL OF THE FALSE DISCOVERY RATE IN MULTIPLE TESTING UNDER DEPENDENCY}},
url = {http://www.jstor.org/stable/2674075},
volume = {29},
year = {2001}
}
@article{Candes2011,
abstract = {This paper is about a curious phenomenon. Suppose we have a data matrix, which is the superposition of a low-rank component and a sparse component. Can we recover each component individually? We prove that under some suitable assumptions, it is possible to recover both the low-rank and the sparse components exactly by solving a very convenient convex program called Principal Component Pursuit; among all feasible decompositions, simply minimize a weighted combination of the nuclear norm and of the L1 norm. This suggests the possibility of a principled approach to robust principal component analysis since our methodology and results assert that one can recover the principal components of a data matrix even though a positive fraction of its entries are arbitrarily corrupted. This extends to the situation where a fraction of the entries are missing as well. We discuss an algorithm for solving this optimization problem, and present applications in the area of video surveillance, where our methodology allows for the detection of objects in a cluttered background, and in the area of face recognition, where it offers a principled way of removing shadows and specularities in images of faces.},
annote = {From Duplicate 1 (Robust Principal Component Analysis? - Cand{\'{e}}s, Emmanuel J; Li, Xiaodong; Ma, Yi; Wright, John; Candes, Emmanuel J; Sch{\"{o}}lkopf, B; Smola, A; M{\"{u}}ller, KR)

From Duplicate 1 ( Robust Principal Component Analysis? - Candes, Emmanuel J; Li, Xiaodong; Ma, Yi; Wright, John )
},
archivePrefix = {arXiv},
arxivId = {arXiv:0912.3599v1},
author = {Cand{\`{e}}s, Emmanuel J and Li, Xiaodong and Ma, Yi and Wright, John and Candes, Emmanuel J},
doi = {http://doi.acm.org/10.1145/1970392.1970395},
eprint = {arXiv:0912.3599v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candes et al. - 2009 - Robust Principal Component Analysis.pdf:pdf;:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Principal Component Analysis.html:html},
institution = {Department of Statistics, Stanford University},
isbn = {0-7803-6278-0},
issn = {0004-5411},
journal = {Journal of the ACM},
keywords = {{\&}ell,1-norm minimization,Principal components,duality,low-rank matrices,nuclear-norm minimization,robustness vis-a-vis outliers,sparsity,video surveillance},
number = {3},
pages = {1--37},
pmid = {19686071},
publisher = {ACM Request Permissions},
title = {{Robust Principal Component Analysis?}},
url = {http://link.springer.com/chapter/10.1007/BFb0020217 http://arxiv.org/abs/0912.3599 http://www.springer.com/statistics/statistical+theory+and+methods/book/978-0-387-95442-4 http://arxiv.org/abs/0912.3599{\%}5Cnhttp://doi.acm.org/10.1145/1970392.1970395},
volume = {58},
year = {2009}
}
@incollection{Alder2007,
abstract = {This chapter presents an overview of Wireshark along with its various features and supporting programs. Wireshark is a network analyzer. It can read and process capture files from a number of different products, including other sniffers, routers, and network utilities. It uses the popular Promiscuous Capture Library (libpcap)-based capture format and can easily interfere with other products that use libpcap. Wireshark possesses an easy-to-read and configurable graphical user interface (GUI) along with rich display filter capabilities. The chapter also discusses some of the network architecture and critical points of Wireshark. Network placement is critical for proper analysis and troubleshooting. A good approach to network troubleshooting involves several steps such as recognizing the symptoms; defining the problem, analyzing the problem, isolating the problem, identifying and testing the cause of the problem, solving the problem, and verifying that the problem has been solved. Wireshark can also be used in network system and security administrators. Several tips for running Wireshark in a secure manner along with optimizing methods for Wireshark are also discussed in the chapter.},
author = {Alder, Raven and Burke, Josh and Keefer, Chad and Orebaugh, Angela and Pesce, Larry and Seagren, Eric S.},
booktitle = {How to Cheat at Configuring Open Source Security Tools},
doi = {10.1016/B978-159749170-9/50020-5},
isbn = {9781597491709},
pages = {297--335},
title = {{Introducing Wireshark}},
url = {http://linkinghub.elsevier.com/retrieve/pii/B9781597491709500205},
year = {2007}
}
@inproceedings{Lundberg2010,
annote = {From Duplicate 1 (Analysis of CBRN Sensor Fusion Methods - Lundberg, Scott; Paffenroth, Randy; Yosinski, Jason)

From Duplicate 1 ( 


Analysis of CBRN Sensor Fusion Methods


- Lundberg, S; Paffenroth, R; Yosinski, J )

},
author = {Lundberg, Scott and Paffenroth, Randy and Yosinski, Jason},
booktitle = {Proceedings of Fusion},
editor = {Drummond, O E},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lundberg, Paffenroth, Yosinski - 2010 - Analysis of CBRN Sensor Fusion Methods(2).pdf:pdf},
keywords = {ambiguity,cbrn,covariance consistency,cram,estimation,sensor data fusion,tracking},
title = {{Analysis of CBRN Sensor Fusion Methods}},
volume = {7698},
year = {2010}
}
@article{Castro2004,
author = {Castro, Rui and Coates, Mark and Liang, Gang and Nowak, Robert and Yu, Bin},
doi = {10.1214/088342304000000422},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Castro et al. - 2004 - Network Tomography Recent Developments.pdf:pdf},
issn = {0883-4237},
journal = {Statistical Science},
keywords = {and phrases,identification,network tomography,pseudo-likelihood,topology,tree estimation},
month = {aug},
number = {3},
pages = {499--517},
title = {{Network Tomography: Recent Developments}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.ss/1110999312/},
volume = {19},
year = {2004}
}
@article{Scholkopf1998,
abstract = {A new method for performing a nonlinear form of principal component analysis is proposed. By the use of integral operator kernel functions, one can efficiently compute principal components in high-dimensional feature spaces, related to input space by some nonlinear mapfor instance, the space of all possible five-pixel products in 16 16 images. We give the derivation of the method and present experimental results on polynomial feature extraction for pattern recognition.},
author = {Sch{\"{o}}lkopf, Bernhard and Smola, Alexander and M{\"{u}}ller, Klaus-Robert},
doi = {10.1162/089976698300017467},
institution = {Max-Planck-Institut {\{}f{\"{u}}r{\}} biologische Kybernetik},
issn = {08997667},
journal = {Neural Computation},
number = {5},
pages = {1299--1319},
pmid = {21939901},
publisher = {MIT Press},
title = {{Nonlinear Component Analysis as a Kernel Eigenvalue Problem}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976698300017467},
volume = {10},
year = {1998}
}
@article{pvclust,
abstract = {Pvclust is an add-on package for a statistical software R to assess the uncertainty in hierarchical cluster analysis. Pvclust can be used easily for general statistical problems, such as DNA microarray analysis, to perform the bootstrap analysis of clustering, which has been popular in phylogenetic analysis. Pvclust calculates probability values (p-values) for each cluster using bootstrap resampling techniques. Two types of p-values are available: approximately unbiased (AU) p-value and bootstrap probability (BP) value. Multiscale bootstrap resampling is used for the calculation of AU p-value, which has superiority in bias over BP value calculated by the ordinary bootstrap resampling. In addition the computation time can be enormously decreased with parallel computing option.Availability: The program is freely distributed under GNU General Public License (GPL) and can directly be installed from CRAN (http://cran.r-project.org/), the official R package archive. The instruction and program source code are available at http://www.is.titech.ac.jp/{\~{}}shimo/prog/pvclustContact:ryota.suzuki@is.titech.ac.jp},
address = {Oxford, UK},
author = {Suzuki, Ryota and Shimodaira, Hidetoshi},
doi = {10.1093//bioinformatics//btl117},
issn = {1367-4803},
journal = {Bioinformatics},
month = {jun},
number = {12},
pages = {1540--1542},
publisher = {Oxford University Press},
title = {{Pvclust: an R package for assessing the uncertainty in hierarchical clustering}},
url = {http://bioinformatics.oxfordjournals.org/content/22/12/1540.short http://dx.doi.org/10.1093/bioinformatics/btl117},
volume = {22},
year = {2006}
}
@misc{Cai2008a,
abstract = {. Finding a solution of a linear equation Au = f with various minimization properties arises from many applications. One of such applications is compressed sensing, where an efficient and robust-to-noise algorithm to find a minimal ℓ1 norm solution is needed. This means that the algorithm should be tailored for large scale and completely dense matrices A, while Au and A T u can be computed by fast transforms and the solution to seek is sparse. Recently, a simple and fast algorithm based on linearized Bregman iteration was proposed in [28, 32] for this purpose. This paper is to analyze the convergence of linearized Bregman iterations and the minimization properties of their limit. Based on our analysis here, we derive also a new algorithm that is proven to be convergent with a rate. Furthermore, the new algorithm is as simple and fast as the algorithm given in [28, 32] in approximating a minimal ℓ1 norm solution of Au = f as shown by numerical simulations. Hence, it can be used as another choice of an efficient tool in compressed sensing. 1. Introduction. Let A ∈ R m×n with n{\textgreater} m and f ∈ R m be given. The aim of a basis pursuit problem is to find u ∈ R n by solving the following constrained minimization problem min},
author = {Cai, Jian-feng and Osher, Stanley and Shen, Zuowei},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Osher, Shen - 2008 - Fast Linearized Bregman Iteration for Compressed Sensing.pdf:pdf},
pages = {08--37},
publisher = {and Sparse Denoising, 2008. UCLA CAM Reprots},
title = {{Fast Linearized Bregman Iteration for Compressed Sensing}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.139.7640},
year = {2008}
}
@book{HastieTrevorTibshiraniRobertFriedman2009,
abstract = {During the past decade there has been an explosion in computation and information technology. With it have come vast amounts of data in a variety of fields such as medicine, biology, finance, and marketing. The challenge of understanding these data has led to the development of new tools in the field of statistics, and spawned new areas such as data mining, machine learning, and bioinformatics. Many of these tools have common underpinnings but are often expressed with different terminology. This book describes the important ideas in these areas in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It is a valuable resource for statisticians and anyone interested in data mining in science or industry. The book's coverage is broad, from supervised learning (prediction) to unsupervised learning. The many topics include neural networks, support vector machines, classification trees and boosting---the first comprehensive treatment of this topic in any book.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {{Hastie, Trevor, Tibshirani, Robert, Friedman}, Jerome},
booktitle = {Springer series in statistics},
doi = {10.1007/978-0-387-84858-7},
eprint = {arXiv:1011.1669v3},
isbn = {978-0-387-84858-7},
issn = {00111287},
keywords = {Data Mining,Inference,Neural Nets,Prediction,Statistical Learning},
pages = {282},
pmid = {12377617},
title = {{The Elements of Statistical LearningData Mining, Inference, and Prediction, Second Edition}},
year = {2009}
}
@article{Cai2010,
archivePrefix = {arXiv},
arxivId = {arXiv:0810.3286v1},
author = {Cai, JF F and Cand{\`{e}}s, EJ J and Shen, Z},
eprint = {arXiv:0810.3286v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Cand{\`{e}}s, Shen - 2010 - A singular value thresholding algorithm for matrix completion.pdf:pdf},
journal = {SIAM Journal on Optimization},
keywords = {applied and computational mathematics,ca 91125,caltech,department of mathematics,ek laboratories,national university of singapore,pasadena,singapore 117543},
pages = {1--28},
title = {{A singular value thresholding algorithm for matrix completion}},
url = {http://epubs.siam.org/doi/pdf/10.1137/080738970},
year = {2010}
}
@misc{weave,
howpublished = {http://docs.scipy.org/doc/scipy/reference/tutorial/weave.html},
title = {{Weave (scipy.weave) — SciPy v0.13.0 Reference Guide}},
url = {http://docs.scipy.org/doc/scipy/reference/tutorial/weave.html}
}
@article{Anandkumar2011,
author = {Anandkumar, Animashree and Hassidim, A},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Anandkumar, Hassidim - 2011 - Topology discovery of sparse random graphs with few participants.pdf:pdf},
journal = {ACM SIGMETRICS Performance},
title = {{Topology discovery of sparse random graphs with few participants}},
url = {http://dl.acm.org/citation.cfm?id=2007146},
year = {2011}
}
@article{Chen2011,
abstract = {This paper considers the problem of matrix completion, when some number of the columns are arbitrarily corrupted, potentially by a malicious adversary. It is well-known that standard algorithms for matrix completion can return arbitrarily poor results, if even a single column is corrupted. What can be done if a large number, or even a constant fraction of columns are corrupted? In this paper, we study this very problem, and develop an efficient algorithm for its solution. Our results show that with a vanishing fraction of observed entries, it is nevertheless possible to succeed in performing matrix completion, even when the number of corrupted columns grows. When the number of corruptions is as high as a constant fraction of the total number of columns, we show that again exact matrix completion is possible, but in this case our algorithm requires many more -- a constant fraction -- of observations. One direct application comes from robust collaborative filtering. Here, some number of users are so-called manipulators, and try to skew the predictions of the algorithm. Significantly, our results hold without any assumptions on the number, locations or values of the observed entries of the manipulated columns. In particular, this means that manipulators can act in a completely adversarial manner.},
archivePrefix = {arXiv},
arxivId = {1102.2254},
author = {Chen, Yudong and Xu, Huan and Caramanis, Constantine and Sanghavi, Sujay},
eprint = {1102.2254},
journal = {arXiv preprint arXiv:1102.2254},
month = {feb},
pages = {32},
title = {{Robust matrix completion with corrupted columns}},
url = {http://arxiv.org/abs/1102.2254},
year = {2011}
}
@article{Zhu2005,
author = {Zhu, X},
title = {{Semi-supervised learning literature survey}},
url = {http://scholar.google.com/scholar?hl=en{\&}q=semi-supervised+learning{\&}btnG={\&}as{\_}sdt=1,22{\&}as{\_}sdtp={\#}2 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Semi-supervised+learning+literature+survey{\#}0},
year = {2005}
}
@article{Kwitt2007,
abstract = {This paper points out the need for unsupervised anomaly detection in the context of instrusion detection systems. Our work is based on an approach which employs principal component analysis (PCA) in order to detect anomalies in measurements of certain network traffic parameters. We discuss the problem of contaminated training data and propose to use PCA on the basis of robust estimators to overcome the necessity of a supervised preprocessing step.},
author = {Kwitt, Roland and Hofmann, Ulrich},
doi = {10.1109/ICCGI.2007.62},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kwitt, Hofmann - 2007 - Unsupervised Anomaly Detection in Network Traffic by Means of Robust PCA.pdf:pdf},
isbn = {0-7695-2798-1},
journal = {2007 International Multi-Conference on Computing in the Global Information Technology (ICCGI'07)},
keywords = {Data security,Detection algorithms,Detectors,Internet,Intrusion detection,PCA,Principal component analysis,Robustness,Statistics,Telecommunication traffic,Training data,network traffic,principal component analysis,security of data,supervised preprocessing step,telecommunication traffic,unsupervised anomaly detection},
pages = {37--37},
title = {{Unsupervised Anomaly Detection in Network Traffic by Means of Robust PCA}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4137092},
year = {2007}
}
@article{Mairal2009,
author = {Mairal, J and Bach, F and Ponce, J and Sapiro, G},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Mairal et al. - 2009 - Online dictionary learning for sparse coding.pdf:pdf},
journal = {{\ldots}  Conference on Machine Learning},
title = {{Online dictionary learning for sparse coding}},
url = {http://dl.acm.org/citation.cfm?id=1553463},
year = {2009}
}
@inproceedings{OhSas05b,
abstract = {This paper considers the problem of tracking objects with sparsely
located binary sensors. Tracking with a sensor network is a challenging
task due to the inaccuracy of sensors and difficulties in sensor
network localization. Based on the simplest sensor model, in which
each sensor reports only a binary value indicating whether an object
is present near the sensor or not, we present an optimal distributed
tracking algorithm which does not require sensor network localization.
The tracking problem is formulated as a hidden state estimation problem
over the finite state space of sensors. Then a distributed tracking
algorithm is derived from the Viterbi algorithm. We also describe
provably good pruning strategies for scalability of the algorithm
and show the conditions under which the algorithm is robust against
false detections. The algorithm is also extended to handle non-disjoint
sensing regions and to track multiple moving objects. Since the computation
and storage of track information are done in a completely distributed
manner, the method is robust against node failures and transmission
failures. In addition, the use of binary sensors makes the proposed
algorithm suitable for many sensor network applications.},
address = {Los Angeles, CA},
author = {Oh, Songhwai and Sastry, Shankar},
booktitle = {International Conference on Information Processing in Sensor Networks (IPSN)},
month = {apr},
title = {{Tracking on a Graph}},
url = {http://www.eecs.berkeley.edu/{~}sho/research.html},
year = {2005}
}
@inproceedings{Czyz2014,
address = {New York, New York, USA},
author = {Czyz, Jakub and Kallitsis, Michael and Gharaibeh, Manaf and Papadopoulos, Christos and Bailey, Michael and Karir, Manish},
booktitle = {Proceedings of the 2014 Conference on Internet Measurement Conference - IMC '14},
doi = {10.1145/2663716.2663717},
isbn = {9781450332132},
keywords = {DDoS,NTP,darknet},
month = {nov},
pages = {435--448},
publisher = {ACM Press},
title = {{Taming the 800 Pound Gorilla}},
url = {http://dl.acm.org/citation.cfm?id=2663716.2663717},
year = {2014}
}
@article{Axelsson2000a,
author = {Axelsson, S},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Axelsson - 2000 - The base-rate fallacy and the difficulty of intrusion detection.pdf:pdf},
journal = {ACM Transactions on Information and System Security (TISSEC)},
number = {3},
pages = {18--205},
title = {{The base-rate fallacy and the difficulty of intrusion detection}},
url = {http://dl.acm.org/citation.cfm?id=357849},
volume = {3},
year = {2000}
}
@article{saenpholphat2004conditional,
author = {Saenpholphat, Varaporn and Zhang, Ping},
journal = {International Journal of Mathematics and Mathematical Sciences},
number = {38},
pages = {1997--2017},
publisher = {Hindawi Publishing Corporation},
title = {{Conditional resolvability in graphs: a survey}},
volume = {2004},
year = {2004}
}
@article{Lakhina2004,
abstract = {Network traffic arises from the superposition of Origin-Destination (OD) flows. Hence, a thorough understanding of OD flows is essential for modeling network traffic, and for addressing a wide variety of problems including traffic engineering, traffic matrix estimation, capacity planning, forecasting and anomaly detection. However, to date, OD flows have not been closely studied, and there is very little known about their properties.We present the first analysis of complete sets of OD flow time-series, taken from two different backbone networks (Abilene and Sprint-Europe). Using Principal Component Analysis (PCA), we find that the set of OD flows has small intrinsic dimension. In fact, even in a network with over a hundred OD flows, these flows can be accurately modeled in time using a small number (10 or less) of independent components or dimensions.We also show how to use PCA to systematically decompose the structure of OD flow timeseries into three main constituents: common periodic trends, short-lived bursts, and noise. We provide insight into how the various constitutents contribute to the overall structure of OD flows and explore the extent to which this decomposition varies over time.},
author = {Lakhina, Anukool and Papagiannaki, Konstantina and Crovella, Mark and Diot, Christophe and Kolaczyk, Eric D. and Taft, Nina},
doi = {10.1145/1012888.1005697},
isbn = {1581138733},
issn = {01635999},
journal = {ACM SIGMETRICS Performance Evaluation Review},
number = {1},
pages = {61},
title = {{Structural analysis of network traffic flows}},
volume = {32},
year = {2004}
}
@inproceedings{Bandara2011,
address = {Bonn, Germany},
author = {Bandara, V. and Jayasumana, A. P.},
booktitle = {Proc. 36th Conference on Local Computer Networks},
title = {{Extracting Baseline Patterns in Internet Traffic Using Robust Principle Components}},
year = {2011}
}
@misc{InfreqDataFinalReport1Option,
author = {Slocumb, B and Trawick, D and Paffenroth, R and Yosinski, J},
institution = {Numerica Corporation},
month = {jan},
number = {Contract W9113M-07-C-0007},
title = {{Association of Critical, Infrequent Data for Network-Centric Multiple Frame Association for Distributed Multiple Target Tracking}},
type = {SIAP JPO SBIR Phase I Option Final Report},
year = {2008}
}
@misc{Python2013,
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Python Programming Language – Official Website.html:html},
howpublished = {http://www.python.org/},
keywords = {python programming language object oriented web fr},
title = {{Python Programming Language – Official Website}},
url = {http://www.python.org/},
urldate = {2013-06-12}
}
@article{Beerliova2006,
abstract = {Due to its fast, dynamic, and distributed growth process, it is hard to obtain an accurate map of the Internet. In many cases, such a map-representing the structure of the Internet as a graph with nodes and links-is a prerequisite when investigating properties of the Internet. A common way to obtain such maps is to make certain local measurements at a small subset of the nodes, and then to combine these in order to "discover" (an approximation of) the actual graph. Each of these measurements is potentially quite costly. It is thus a natural objective to minimize the number of measurements which still discover the whole graph. We formalize this problem as a combinatorial optimization problem and consider it for two different models characterized by different types of measurements. We give several upper and lower bounds on the competitive ratio (for the online network discovery problem) and the approximation ratio (for the offline network verification problem) in both models. Furthermore, for one of the two models, we compare four simple greedy strategies in an experimental analysis},
author = {Beerliova, Zuzana and Eberhard, Felix and Erlebach, Thomas and Hall, Alexander and Hoffmann, Michael and Mihal'{\'{a}}k, Mat{\'{u}}{\v{s}} and Ram, L. Shankar},
doi = {10.1109/JSAC.2006.884015},
isbn = {354034375X},
issn = {07338716},
journal = {IEEE Journal on Selected Areas in Communications},
keywords = {Approximation algorithms,Complex networks,Internet discovery,Online algorithms,Random graphs},
pages = {2168--2181},
title = {{Network discovery and verification}},
volume = {24},
year = {2006}
}
@misc{fpc,
author = {Hennig, Christian},
month = {aug},
title = {{: Flexible procedures for clustering. R package version 2.1-9.}},
url = {http://cran.r-project.org/package=fpc},
year = {2014}
}
@article{Kakade2003,
address = {New York, New York, USA},
author = {Kakade, Sham and Kearns, Michael and Langford, John and Ortiz, Luis},
doi = {10.1145/779928.779934},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kakade et al. - 2003 - Correlated equilibria in graphical games.pdf:pdf},
isbn = {158113679X},
journal = {Proceedings of the 4th ACM conference on Electronic commerce - EC '03},
keywords = {correlated equilibria,game theory,graphical,graphical games},
pages = {42--47},
publisher = {ACM Press},
title = {{Correlated equilibria in graphical games}},
url = {http://portal.acm.org/citation.cfm?doid=779928.779934},
year = {2003}
}
@article{Shen2007a,
author = {Shen, Dan and Chen, Genshe and Cruz, Jr., Jose B. and Haynes, Leonard and Kruger, Martin and Blasch, Erik},
doi = {10.1117/12.720090},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2007 - A Markov game theoretic data fusion approach for cyber situational awareness.pdf:pdf},
issn = {0277786X},
journal = {Proceedings of SPIE},
keywords = {cyber defense,data mining,game,impact assessment,information fusion,networks security,situation awareness,theory},
number = {1},
pages = {65710F--65710F--12},
publisher = {Spie},
title = {{A Markov game theoretic data fusion approach for cyber situational awareness}},
url = {http://link.aip.org/link/PSISDG/v6571/i1/p65710F/s1{\&}Agg=doi},
volume = {3},
year = {2007}
}
@article{Leskovec2014,
author = {Leskovec, J and Krevl, A},
title = {{{\{}SNAP Datasets{\}}:{\{}Stanford{\}} Large Network Dataset Collection}},
url = {http://www.citeulike.org/group/19235/article/13433079},
year = {2014}
}
@article{Choi2010,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.4644v1},
author = {Choi, DS and Wolfe, PJ},
eprint = {arXiv:1011.4644v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Choi, Wolfe - 2010 - Stochastic blockmodels with growing number of classes.pdf:pdf},
journal = {Arxiv preprint arXiv},
title = {{Stochastic blockmodels with growing number of classes}},
url = {http://www.heinz.cmu.edu/Faculty{\_}Search{\_}Data Analysis/Choi, Dave/Job Market Papers{\_}Choi.pdf},
year = {2010}
}
@article{Zhu2010,
author = {Zhu, X},
journal = {Encyclopedia of Machine Learning},
title = {{Semi-supervised learning}},
url = {http://link.springer.com/content/pdf/10.1007/978-0-387-30164-8{\_}749.pdf},
year = {2010}
}
@misc{Abdi2010,
abstract = {Principal component analysis (pca) is a multivariate technique that analyzes a data table in which observations are described by several inter-correlated quantitative dependent variables. Its goal is to extract the important information from the table, to represent it as a set of new orthogonal variables called principal components, and to display the pattern of similarity of the observations and of the variables as points in maps. The quality of the pca model can be evaluated using cross-validation techniques such as the bootstrap and the jackknife. Pca can be generalized as correspondence analysis (ca) in order to handle qualitative variables and as multiple factor analysis (mfa) in order to handle heterogenous sets of variables. Mathematically, pca depends upon the eigen-decomposition of positive semi-definite matrices and upon the singular value decomposition (svd) of rectangular matrices.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Abdi, Herv{\'{e}} and Williams, Lynne J.},
booktitle = {Wiley Interdisciplinary Reviews: Computational Statistics},
doi = {10.1002/wics.101},
eprint = {arXiv:1011.1669v3},
isbn = {1939-0068},
issn = {19395108},
number = {4},
pages = {433--459},
pmid = {20931840},
title = {{Principal component analysis}},
volume = {2},
year = {2010}
}
@article{Hunter2007,
abstract = {Matplotlib is a 2D graphics package used for Python for application development, interactive scripting,and publication-quality image generation across user interfaces and operating systems},
author = {Hunter, John D.},
doi = {10.1109/MCSE.2007.55},
isbn = {1521-9615 VO  - 9},
issn = {15219615},
journal = {Computing in Science and Engineering},
pages = {99--104},
title = {{Matplotlib: A 2D graphics environment}},
volume = {9},
year = {2007}
}
@article{Bollobas2013,
abstract = {The metric dimension of a graph G is the minimum number of vertices in a subset S of the vertex set of G such that all other vertices are uniquely determined by their distances to the vertices in S . In this paper we investigate the metric dimension of the random graph G ( n,p ) for a wide range of probabilities p = p ( n ).},
archivePrefix = {arXiv},
arxivId = {arXiv:1208.3801v1},
author = {Bollob{\'{a}}s, B{\'{e}}la and Mitsche, Dieter and Pra{\l}at, Pawe{\l}},
eprint = {arXiv:1208.3801v1},
issn = {10778926},
journal = {Electronic Journal of Combinatorics},
title = {{Metric dimension for random graphs}},
volume = {20},
year = {2013}
}
@article{Muller1988,
abstract = {This article summarizes some main results in modern portfolio theory. First, the Markowitz approach is presented. Then the capital asset pricing model is derived and its empirical testability is discussed. Afterwards Neumann-Morgenstern utility theory is applied to the portfolio problem. Finally, it is shown how optimal risk allocation in an economy may lead to portfolio insurance.},
author = {Muller, Heinz H.},
journal = {Astin Bulletin},
keywords = {capital asset pricing model,markowitz approach,modern portfolio theory,neumann-morgenstern utilities,portfolio insurance},
pages = {9--27},
title = {{Modern portfolio theory: some main results}},
volume = {18},
year = {1988}
}
@article{Ashlagi2008,
author = {Ashlagi, Itai and Monderer, Dov and Tennenholtz, Moshe},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ashlagi, Monderer, Tennenholtz - 2008 - On the value of correlation.pdf:pdf},
journal = {Journal of artificial intelligence research},
number = {613},
title = {{On the value of correlation}},
volume = {575},
year = {2008}
}
@article{Lee2008,
archivePrefix = {arXiv},
arxivId = {arXiv:0811.0121v1},
author = {Lee, Ann B and Wasserman, Larry},
eprint = {arXiv:0811.0121v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Wasserman - 2010 - Spectral Connectivity Analysis.pdf:pdf},
journal = {Journal of the American Statistical Association},
keywords = {diffusion,graph laplacian,kernels,manifold learning,smoothing,spectral clustering},
number = {491},
pages = {1241--1255},
title = {{Spectral Connectivity Analysis}},
volume = {105},
year = {2010}
}
@article{candes09ex,
author = {Cand{\`{e}}s, EJ and Recht, B},
journal = {Foundations of Computational Mathematics},
title = {{Exact matrix completion via convex optimization}},
url = {http://link.springer.com/article/10.1007/s10208-009-9045-5},
year = {2009}
}
@article{Candes2009foo,
author = {Cand{\`{e}}s, E J and Tao., T},
journal = {IEEE Trans. Inform. Theory,},
number = {5},
pages = {2053--2080},
title = {{The power of convex relaxation: Near-optimal matrix completion.}},
volume = {56},
year = {2009}
}
@inproceedings{Brauckhoff2009,
abstract = {Spatial Principal Component Analysis (PCA) has been proposed for network-wide anomaly detection. A recent work has shown that PCA is very sensitive to calibration settings. Unfortunately, the authors did not provide further explanations for this observation. In this paper, we fill this gap and provide the reasoning behind the found discrepancies. We revisit PCA for anomaly detection and evaluate its performance on our data. We develop a slightly modified version of PCA that uses only data from a single router. Instead of correlating data across different spatial measurement points, we correlate the data across different metrics. With the help of the analyzed data, we explain the pitfalls of PCA and underline our argumentation with measurement results. We show that the main problem is that PCA fails to capture temporal correlation. We propose a solution to deal with this problem by replacing PCA with the Karhunen-Loeve transform. We find that when we consider temporal correlation, anomaly detection results are significantly improved.},
author = {Brauckhoff, Daniela and Salamatian, Kave and May, Martin},
booktitle = {Proceedings - IEEE INFOCOM},
doi = {10.1109/INFCOM.2009.5062248},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Brauckhoff, Salamatian, May - 2009 - Applying PCA for traffic anomaly detection Problems and solutions.pdf:pdf},
isbn = {9781424435135},
issn = {0743166X},
pages = {2866--2870},
title = {{Applying PCA for traffic anomaly detection: Problems and solutions}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5062248},
year = {2009}
}
@article{candes07sp,
author = {Cand{\`{e}}s, E and Romberg, J},
journal = {Inverse Problems},
month = {jun},
number = {3},
pages = {969--986},
title = {{Sparsity and Incoherence in Compressive Sampling}},
volume = {23},
year = {2007}
}
@article{Xu2010a,
author = {Xu, Huan and Caramanis, Constantine and Sanghavi, Sujay},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Caramanis, Sanghavi - 2010 - Robust PCA via Outlier Pursuit.pdf:pdf},
journal = {Computer},
pages = {1--29},
title = {{Robust PCA via Outlier Pursuit}},
year = {2010}
}
@article{Xie2009,
author = {Xie, Y and Yu, SZ},
journal = {Networking, IEEE/AcM Transactions on},
title = {{Monitoring the application-layer DDoS attacks for popular websites}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=4548145},
year = {2009}
}
@misc{RDevelopmentCoreTeam2013,
abstract = {R Core Team (2013). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. ISBN 3-900051-07-0, URL http://www.R-project.org/.},
author = {{R Development Core Team}},
booktitle = {R Foundation for Statistical Computing, Vienna, Austria.},
isbn = {3900051070},
issn = {16000706},
title = {{R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.}},
year = {2013}
}
@phdthesis{Mardani2015,
author = {Mardani, Morteza (University of Minnesota)},
title = {{Leveraging Sparsity and Low Rank for Large-Scale Networks and Data Science}},
year = {2015}
}
@misc{ip2location,
author = {Ip2location},
title = {http://www.ip2location.com},
year = {2015}
}
@techreport{Gharaibeh15a,
author = {Gharaibeh, Manaf and Zhang, Han and Papadopoulos, Christos and Heidemann, John},
institution = {Department of Computer Science},
keywords = {IP geolocation},
month = {nov},
number = {CS-15-103},
title = {{Assessing Co-Locality of {\{}IP{\}} Blocks}},
url = {http://www.isi.edu/{~}johnh/PAPERS/Gharaibeh15a.html},
year = {2015}
}
@book{Parker1998,
author = {Parker, Donn B.},
isbn = {0471163783},
publisher = {John Wiley {\&} Sons},
title = {{Fighting Computer Crime}},
year = {1998}
}
@article{Perry2013,
abstract = {Network data often take the form of repeated interactions between senders and receivers tabulated over time. A primary question to ask of such data is which traits and behaviors are predictive of interaction. To answer this question, a model is introduced for treating directed interactions as a multivariate point process: a Cox multiplicative intensity model using covariates that depend on the history of the process. Consistency and asymptotic normality are proved for the resulting partial-likelihood-based estimators under suitable regularity conditions, and an efficient fitting procedure is described. Multicast interactions--those involving a single sender but multiple receivers--are treated explicitly. The resulting inferential framework is then employed to model message sending behavior in a corporate e-mail network. The analysis gives a precise quantification of which static shared traits and dynamic network effects are predictive of message recipient selection.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1703v3},
author = {Perry, Patrick O and Wolfe, Patrick J},
doi = {10.1111/rssb.12013},
eprint = {arXiv:1011.1703v3},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Perry, Wolfe - 2013 - Point process modeling for directed interaction networks.pdf:pdf},
issn = {13697412},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {cox proportional hazards model,ence,network data analysis,partial likelihood infer-,point processes},
number = {5},
pages = {1--36},
title = {{Point process modeling for directed interaction networks}},
volume = {75},
year = {2013}
}
@article{Al-Homidan2005,
author = {Al-Homidan, Suliman and Wolkowicz, Henry},
doi = {10.1016/j.laa.2005.03.021},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Al-Homidan, Wolkowicz - 2005 - Approximate and exact completion problems for Euclidean distance matrices using semidefinite programming.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {completion problems,euclidean distance matrix,nearest matrix approximation,semidefinite},
month = {sep},
pages = {109--141},
title = {{Approximate and exact completion problems for Euclidean distance matrices using semidefinite programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0024379505001898},
volume = {406},
year = {2005}
}
@misc{MULLER1989,
abstract = {All investors, be they private individuals, trustees or professionals are faced with an extraordinary range of options when it comes to building and maintaining a portfolio. At the point in time when the portfolio is created decisions have to be made as to what assets to include and in what proportion. This article provides the reader with an understanding of the foundations underpinning Modern Portfolio Theory that provides a framework within which to make sensible asset allocation decisions.},
author = {M{\"{U}}LLER, Heinz H.},
booktitle = {ASTIN Bulletin},
doi = {10.2143/AST.19.3.2014899},
isbn = {978-1-118-41720-1$\backslash$r1-118-41720-8$\backslash$r978-1-118-37052-0},
issn = {1363-1780},
pages = {9--27},
title = {{Modern Portfolio Theory}},
volume = {19},
year = {1989}
}
@article{Mikut2011,
abstract = {The development and application of data mining algorithms requires$\backslash$nthe use of powerful software tools. As the number of available tools$\backslash$ncontinues to grow, the choice of the most suitable tool becomes increasingly$\backslash$ndifficult. This paper attempts to support the decision-making process$\backslash$nby discussing the historical development and presenting a range of$\backslash$nexisting state-of-the-art data mining and related tools. Furthermore,$\backslash$nwe propose criteria for the tool categorization based on different$\backslash$nuser groups, data structures, data mining tasks and methods, visualization$\backslash$nand interaction styles, import and export options for data and models,$\backslash$nplatforms, and license policies. These criteria are then used to$\backslash$nclassify data mining tools into nine different types. The typical$\backslash$ncharacteristics of these types are explained and a selection of the$\backslash$nmost important tools is categorized. This paper is organized as follows:$\backslash$nthe first section Historical Development and State-of-the-Art highlights$\backslash$nthe historical development of data mining software until present;$\backslash$nthe criteria to compare data mining software are explained in the$\backslash$nsecond section Criteria for Comparing Data Mining Software. The last$\backslash$nsection Categorization of Data Mining Software into Different Types$\backslash$nproposes a categorization of data mining software and introduces$\backslash$ntypical software tools for the different types. {\^{A}}{\textcopyright} 2011 John Wiley$\backslash$n{\&} Sons, Inc. WIREs Data Mining Knowl Discov 2011 1 431-443 DOI: 10.1002/widm.24},
author = {Mikut, Ralf and Reischl, Markus},
doi = {10.1002/widm.24},
isbn = {1942-4795},
issn = {19424787},
journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
pages = {431--443},
title = {{Data mining tools}},
volume = {1},
year = {2011}
}
@article{Zhao2014,
author = {Zhao, Qian and Meng, D and Xu, Z and Zuo, W and Zhang, L},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2014 - Robust Principal Component Analysis with Complex Noise.pdf:pdf},
journal = {Proceedings of the 31 st International Conference on Machine Learning},
title = {{Robust Principal Component Analysis with Complex Noise}},
url = {http://www4.comp.polyu.edu.hk/{~}cslzhang/paper/MoG{\_}RPCA.pdf},
year = {2014}
}
@article{Calderbank2009,
abstract = {In this paper, we provide theoretical results to show that compressed learning, learning directly in the compressed domain, is possible. In Particular, we provide tight bounds demonstrating that the linear kernel SVMs classifier in the measurement domain, with high probability, has true accuracy close to the accuracy of the best linear threshold classifier in the data domain. We show that this is beneficial both from the compressed sensing and the machine learning points of view. Furthermore, we indicate that for a family of well-known compressed sensing matrices, compressed learning is universal, in the sense that learning and classification in the measurement domain works provided that the data are sparse in some, even unknown, basis. Moreover, we show that our results are also applicable to a family of smooth manifold-learning tasks. Finally, we support our claims with experimental results. 1},
author = {Calderbank, Robert and Jafarpour, S and Schapire, Robert E},
institution = {CiteSeerX - Scientific Literature Digital Library and Search Engine [http://citeseerx.ist.psu.edu/oai2] (United States)},
journal = {Preprint},
pages = {10},
publisher = {Citeseer},
title = {{Compressed learning: Universal sparse dimensionality reduction and learning in the measurement domain}},
url = {http://dsp.rice.edu/files/cs/cl.pdf},
year = {2009}
}
@article{Mairal2009a,
author = {Mairal, J and Ponce, J and Sapiro, G},
journal = {Advances in neural  {\ldots}},
title = {{Supervised dictionary learning}},
url = {http://papers.nips.cc/paper/3448-supervised-dictionary-learning},
year = {2009}
}
@book{Bar-Shalom1995,
address = {Storrs, CT},
author = {Bar-Shalom, Y and Li, X R},
publisher = {YBS Publishing},
title = {{Multitarget Multisensor Tracking: Principles and Techniques}},
year = {1995}
}
@book{Diestel2005,
abstract = {Previous studies have suggested that some graph properties of protein interaction networks might be related with gene morbidity. In particular, it has been suggested that when a polymorphism affects a gene, it is more likely to produce a disease if the node degree in the interaction network is higher than for other genes. However, these results do not take into account the possible bias introduced by the variance in the amount of information available for different genes. This work models the relationship between the morbidity associated with a gene and the degrees of the nodes in the protein interaction network controlling the amount of information available in the literature. A set of 7461 genes and 3665 disease identifiers reported in the Online Mendelian Inheritance in Man (OMIM) was mined jointly with 9630 nodes and 38756 interactions of the Human Proteome Resource Database (HPRD). The information available from a gene was measured through PubMed mining. Results suggest that the correlation between the degree of a node in the protein interaction network and its morbidity is largely contributed by the information available from the gene. Even though the results suggest a positive correlation between the degree of a node and its morbidity while controlling the information factor, we believe this correlation has to be taken with caution for it can be affected by other factors not taken into account in this study.},
author = {Diestel, Reinhard},
booktitle = {New York},
doi = {10.1109/IEMBS.2010.5626521},
isbn = {3540609180},
issn = {1557170X},
keywords = {graph theory},
mendeley-tags = {graph theory},
pages = {803--6},
pmid = {21096114},
publisher = {Springer Verlag},
title = {{Graph Theory}},
volume = {173},
year = {2005}
}
@article{Hyvarinen2000,
abstract = {A fundamental problem in neural network research, as well as in many other disciplines, is finding a suitable representation of multivariate data, i.e. random vectors. For reasons of computational and conceptual simplicity, the representation is often sought as a linear transformation of the original data. In other words, each component of the representation is a linear combination of the original variables. Well-known linear transformation methods include principal component analysis, factor analysis, and projection pursuit. Independent component analysis (ICA) is a recently developed method in which the goal is to find a linear representation of non-Gaussian data so that the components are statistically independent, or as independent as possible. Such a representation seems to capture the essential structure of the data in many applications, including feature extraction and signal separation. In this paper, we present the basic theory and applications of ICA, and our recent work on the subject.},
author = {Hyv{\"{a}}rinen, a and Oja, E},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hyv{\"{a}}rinen, Oja - 2000 - Independent component analysis algorithms and applications.pdf:pdf},
issn = {0893-6080},
journal = {Neural networks : the official journal of the International Neural Network Society},
keywords = {Algorithms,Artifacts,Brain,Brain: physiology,Humans,Magnetoencephalography,Neural Networks (Computer),Normal Distribution},
number = {4-5},
pages = {411--30},
pmid = {10946390},
title = {{Independent component analysis: algorithms and applications.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/10946390},
volume = {13},
year = {2000}
}
@article{Davenport2010,
abstract = {The emergence of low-cost sensing architectures for diverse modalities has made it possible to deploy sensor networks that capture a single event from a large number of vantage points and using multiple modalities. In many scenarios, these networks acquire large amounts of very high-dimensional data. For example, even a relatively small network of cameras can generate massive amounts of high-dimensional image and video data. One way to cope with this data deluge is to exploit low-dimensional data models. Manifold models provide a particularly powerful theoretical and algorithmic framework for capturing the structure of data governed by a small number of parameters, as is often the case in a sensor network. However, these models do not typically take into account dependencies among multiple sensors. We thus propose a new joint manifold framework for data ensembles that exploits such dependencies. We show that joint manifold structure can lead to improved performance for a variety of signal processing algorithms for applications including classification and manifold learning. Additionally, recent results concerning random projections of manifolds enable us to formulate a scalable and universal dimensionality reduction scheme that efficiently fuses the data from all sensors.},
author = {Davenport, M A and Hegde, C and Duarte, M F and Baraniuk, R G},
doi = {10.1109/TIP.2010.2052821},
issn = {10577149},
journal = {IEEE Transactions on Image Processing},
keywords = {camera networks,classification,data fusion,manifold learning,random projections,sensor networks},
number = {10},
pages = {2580--94},
publisher = {IEEE},
title = {{Joint Manifolds for Data Fusion}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20550996},
volume = {19},
year = {2010}
}
@article{Orr1996,
abstract = {In this paper we provide a short overview of the Radial Basis Functions (RBF), their properties, the motivations behind their use and some of their applications. RBF's have been employed for functional approximation in time-series modeling and in pattern classification. They have been shown to implement the Bayesian rule and to model any continuous input- output mapping. RBF's are embedded in a two-layer neural network topology. We present the physical and statistical significance of the elements composing the network. We introduce a few RBF training algorithms and we show how RBF networks can be used in real applications.},
author = {Orr, MJL},
journal = {University of Edinburg},
pages = {1--7},
title = {{Introduction to radial basis function networks}},
url = {http://dns2.icar.cnr.it/manco/Teaching/2005/datamining/articoli/RBFNetworks.pdf},
year = {1996}
}
@article{Paffenroth2013b,
author = {Paffenroth, RC and Nong, R and {Du Toit}, P},
journal = {SPIE Optical Engineering+ Applications},
pages = {88570E--88570E},
title = {{On covariance structure in noisy, big data}},
url = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=1746182},
year = {2013}
}
@misc{mandiant,
title = {{Mandiant: Anatomy of an Attack}},
url = {http://www.mandiant.com/threat-landscape/anatomy-of-an-attack/}
}
@misc{LCOM,
howpublished = {https://acc.dau.mil/CommunityBrowser.aspx?id=470290},
title = {{US Air Force Life Cycle Management Center (AFLCMC) Logistics Composite Model (LCOM)}},
url = {https://acc.dau.mil/CommunityBrowser.aspx?id=470290}
}
@article{rs00a,
author = {Roweis, Sam and Saul, Lawrence},
journal = {Science},
month = {dec},
number = {5500},
pages = {2323--2326},
title = {{Nonlinear dimensionality reduction by locally linear embedding}},
url = {http://www.cs.toronto.edu/{~}roweis/lle/publications.html},
volume = {290},
year = {2000}
}
@misc{AFRLIIFinal,
author = {Poore, A B and Klusman, M E and Paffenroth, R and Roberts, S and Novoselov, R and Danford, S and Chan, S},
institution = {Numerica Corporation},
number = {Contract F33615-03-C-1434},
title = {{Network-Centric Multiple Frame Association for Distributed Multiple Target Tracking}},
type = {Air Force SBIR Phase II Final Report},
year = {2006}
}
@book{Shoham2008,
author = {Shoham, Yoav and Leyton-Brown, Kevin},
isbn = {0521899435},
pages = {504},
publisher = {Cambridge University Press},
title = {{Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations}},
url = {http://www.amazon.com/Multiagent-Systems-Algorithmic-Game-Theoretic-Foundations/dp/0521899435},
year = {2008}
}
@book{Fudenberg1991,
author = {Fudenberg, Drew and Tirole, Jean},
isbn = {0262061414},
publisher = {The MIT Press},
title = {{Game Theory}},
url = {http://www.citeulike.org/user/ansobol/article/105659},
year = {1991}
}
@incollection{Parker2002,
author = {Parker, D.},
booktitle = {The Computer Security Handbook},
isbn = {0471412589},
publisher = {John Wiley {\&} Sons},
title = {{Toward a New Framework for Information Security}},
year = {2002}
}
@article{Chen2013a,
abstract = {The paper studies the problem of recovering a spectrally sparse object from a small number of time domain samples. Specifically, the object of interest with ambient dimension {\$}n{\$} is assumed to be a mixture of {\$}r{\$} complex multi-dimensional sinusoids, while the underlying frequencies can assume any value in the unit disk. Conventional compressed sensing paradigms suffer from the {\{}$\backslash$em basis mismatch{\}} issue when imposing a discrete dictionary on the Fourier representation. To address this problem, we develop a novel nonparametric algorithm, called enhanced matrix completion (EMaC), based on structured matrix completion. The algorithm starts by arranging the data into a low-rank enhanced form with multi-fold Hankel structure, then attempts recovery via nuclear norm minimization. Under mild incoherence conditions, EMaC allows perfect recovery as soon as the number of samples exceeds the order of {\$}\backslashmathcal{\{}O{\}}(r\backslashlog{\^{}}{\{}2{\}} n){\$}. We also show that, in many instances, accurate completion of a low-rank multi-fold Hankel matrix is possible when the number of observed entries is proportional to the information theoretical limits (except for a logarithmic gap). The robustness of EMaC against bounded noise and its applicability to super resolution are further demonstrated by numerical experiments.},
archivePrefix = {arXiv},
arxivId = {arXiv:1304.8126v3},
author = {Chen, Yuxin and Chi, Yuejie},
doi = {10.1109/TIT.2014.2343623},
eprint = {arXiv:1304.8126v3},
issn = {00189448},
journal = {arXiv preprint arXiv:1304.8126},
pages = {1--44},
title = {{Robust spectral compressed sensing via structured matrix completion}},
url = {http://arxiv.org/abs/1304.8126},
year = {2013}
}
@article{Felsenstein1985,
abstract = {The recently-developed statistical method known as the "bootstrap" can be used to place confidence intervals on phylogenies. It involves resampling points from one's own data, with replacement, to create a series of bootstrap samples of the same size as the original data. Each of these is analyzed, and the variation among the resulting estimates taken to indicate the size of the error involved in making estimates from the original data. In the case of phylogenies, it is argued that the proper method of resampling is to keep all of the original species while sampling characters with replacement, under the assumption that the characters have been independently drawn by the systematist and have evolved independently.  Majority-rule consensus trees can be used to construct a phylogeny showing all of the inferred monophyletic groups that occurred in a majority of the bootstrap samples. If a group shows up 95{\%} of the time or more, the evidence for it is taken to be statistically significant. Existing computer programs can be used to analyze different bootstrap samples by using weights on the characters, the weight of a character being how many times it was drawn in bootstrap sampling. When all characters are perfectly compatible, as envisioned by Hennig, bootstrap sampling becomes unnecessary; the bootstrap method would show significant evidence for a group if it is defined by three or more characters.},
author = {Felsenstein, J},
doi = {10.2307/2408678},
isbn = {00143820},
issn = {00143820},
journal = {Evolution},
number = {4},
pages = {783--791},
pmid = {283},
title = {{Confidence limits on phylogenies: an approach using the bootstrap}},
volume = {39},
year = {1985}
}
@article{Hu2012,
abstract = {Previousmeasurement-based IP geolocation algorithms have focused on accuracy, studying a few targets with increasingly sophisticated algorithms taking measurements from tens of vantage points (VPs). In this paper, we study how to scale up existing measurement-based geolocation algorithms like Shortest Ping and CBG to cover the whole Internet. We show that with many vantage points, VP proximity to the target is the most important factor affecting accuracy. This observation suggests our new algorithm that selects the best few VPs for each target from many candidates. This ap- proach addresses the main bottleneck to geolocation scala- bility: minimizing traffic into each target (and also out of each VP) while maintaining accuracy. Using this approach we have currently geolocated about 35{\%} of the allocated, unicast, IPv4 address-space (about 85{\%} of the addresses in the Internet that can be directly geolocated). We visu- alize our geolocation results on a web-based address-space browser.},
author = {Hu, Zi and Heidemann, John and Pradkin, Yuri},
doi = {10.1145/2398776.2398790},
isbn = {9781450317054},
journal = {Proceedings of the 2012 ACM conference on Internet measurement conference - IMC '12},
keywords = {a billion targets,bur-,huge amount of traffic,hundreds of vps and,ip geolocation,ipv4,out of each vp,reasonable when both are,small,the product is large,the result is a,while this product is,with},
pages = {123},
title = {{Towards geolocation of millions of IP addresses}},
url = {http://dl.acm.org/citation.cfm?id=2398776.2398790},
year = {2012}
}
@article{dbscan,
abstract = {The clustering algorithm DBSCAN relies on a density-based notion of clusters and is designed to discover clusters of arbitrary shape as well as to distinguish noise. In this paper,we generalize this algorithm in two important directions. Thegeneralized algorithm -called GDBSCAN- can cluster point objects as well as spatially extended objects according to both, their spatial and their nonspatial attributes. In addition, four applications using 2Dpoints (astronomy), 3Dpoints (biology), 5Dpoints (earth science) and2Dpolygons (geography) are presented, demonstrating the applicability of GDBSCAN to real-world problems.},
address = {Hingham, MA, USA},
archivePrefix = {arXiv},
arxivId = {10.1.1.71.1980},
author = {Sander, J and Ester, M and Kriegel, Hp P P and Xu, Xiaowei},
doi = {10.1023/A:1009745219419},
eprint = {10.1.1.71.1980},
isbn = {1384-5810},
issn = {13845810},
journal = {Data Mining and Knowledge {\ldots}},
keywords = {applications,clustering algorithms,efficiency,spatial databases},
month = {jun},
number = {2},
pages = {169--194},
pmid = {15003161},
publisher = {Kluwer Academic Publishers},
title = {{Density-based clustering in spatial databases: The algorithm GDBSCAN and its applications}},
url = {http://link.springer.com/article/10.1023/A:1009745219419},
volume = {194},
year = {1998}
}
@inproceedings{Calderon2011a,
author = {Calderon, C P and Jones, Austin and Lundberg, Scott and Paffenroth, Randy},
booktitle = {Proceedings of SPIE},
keywords = {categorical data,cbrn,data fusion,false alarms,false discovery rate},
pages = {813704},
title = {{A data-driven approach for processing heterogeneous categorical sensor signals}},
url = {http://link.aip.org/link/?PSISDG/8137/813704/1},
volume = {8137},
year = {2011}
}
@article{Xie2011,
author = {Xie, Jichun and Cai, TT and Maris, John and Li, Hongzhe},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2011 - Optimal false discovery rate control for dependent data.pdf:pdf},
keywords = {and phrases,large scale multiple testing,marginal rule,optimal oracle rule,weighted classification},
pages = {417--430},
title = {{Optimal false discovery rate control for dependent data}},
url = {http://www-stat.wharton.upenn.edu/{~}tcai/paper/Dependent-FDR.pdf},
volume = {4},
year = {2011}
}
@article{SURF,
author = {Bay, H and Ess, A and Tuytelaars, T and Gool, Van},
journal = {Computer Vision and Image Understanding, Vol. 110, No. 3, pp. 346--359},
title = {{Speeded Up Robust Features}},
year = {2008}
}
@article{Boyd2010a,
abstract = {Foundations and Trends R in sample Vol. xx, No xx (xxxx) 1118 c xxxx xxxxxxxxx DOI: xxxxxx ... Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers ... Stephen Boyd1, Neal Parikh2, Eric Chu3, Borja Peleato4 and Jonathan Eckstein5},
author = {Boyd, Stephen},
doi = {10.1561/2200000016},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Boyd - 2010 - Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers.pdf:pdf},
institution = {working paper on line, Stanford, Univ},
isbn = {1935823719358245},
issn = {1935-8237},
journal = {Foundations and Trends{\textregistered} in Machine Learning},
number = {1},
pages = {1--122},
publisher = {JMLR. org},
title = {{Distributed Optimization and Statistical Learning via the Alternating Direction Method of Multipliers}},
url = {http://www.nowpublishers.com/product.aspx?product=MAL{\&}doi=2200000016},
volume = {3},
year = {2010}
}
@article{Abdelkefi2010,
author = {Abdelkefi, Atef and Jiang, Yuming and Wang, Wei and Aslebo, Arne and Kvittem, Olav},
doi = {10.1145/1921206.1921217},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Abdelkefi et al. - 2010 - Robust traffic anomaly detection with principal component pursuit.pdf:pdf},
isbn = {9781450304689},
journal = {Proceedings of the ACM CoNEXT Student Workshop on - CoNEXT '10 Student Workshop},
pages = {1},
title = {{Robust traffic anomaly detection with principal component pursuit}},
url = {http://dl.acm.org/citation.cfm?id=1921206.1921217},
year = {2010}
}
@article{systbio,
abstract = {An approximately unbiased (AU) test that uses a newly devised multiscale bootstrap technique was developed for general hypothesis testing of regions in an attempt to reduce test bias. It was applied to maximum-likelihood tree selection for obtaining the confidence set of trees. The AU test is based on the theory of Efron et al. (Proc. Natl. Acad. Sci. USA 93:13429‚{\"{A}}{\`{i}}13434; 1996), but the new method provides higher-order accuracy yet simpler implementation. The AU test, like the Shimodaira‚{\"{A}}{\`{i}}Hasegawa (SH) test, adjusts the selection bias overlooked in the standard use of the bootstrap probability and Kishino‚{\"{A}}{\`{i}}Hasegawa tests. The selection bias comes from comparing many trees at the same time and often leads to overconfidence in the wrong trees. The SH test, though safe to use, may exhibit another type of bias such that it appears conservative. Here I show that the AU test is less biased than other methods in typical cases of tree selection. These points are illustrated in a simulation study as well as in the analysis of mammalian mitochondrial protein sequences. The theoretical argument provides a simple formula that covers the bootstrap probability test, the Kishino‚{\"{A}}{\`{i}}Hasegawa test, the AU test, and the Zharkikh‚{\"{A}}{\`{i}}Li test. A practical suggestion is provided as to which test should be used under particular circumstances.},
author = {Shimodaira, Hidetoshi},
doi = {10.1080/10635150290069913},
isbn = {1063-5157 (Print)},
issn = {1063-5157},
journal = {Systematic Biology},
keywords = {10,10635150290069913,1080,2002,3,492,508,51,an approximately unbiased test,biol,doi,h idetoshi s himodaira,of phylogenetic tree selection,t},
number = {3},
pages = {492--508},
pmid = {12079646},
title = {{An Approximately Unbiased Test of Phylogenetic Tree Selection}},
url = {http://sysbio.oxfordjournals.org/content/51/3/492.abstract},
volume = {51},
year = {2002}
}
@article{Asif2010,
author = {Asif, MS},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asif - 2010 - Sparse signal recovery and dynamic update of the underdetermined system.pdf:pdf},
journal = {, Systems and Computers (ASILOMAR),},
number = {3},
title = {{Sparse signal recovery and dynamic update of the underdetermined system}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5757675},
year = {2010}
}
@article{Tenenbaum2000,
abstract = {Scientists working with large volumes of high-dimensional data, such as global climate patterns, stellar spectra, or human gene distributions, regularly confront the problem of dimensionality reduction: finding meaningful low-dimensional structures hidden in their high-dimensional observations. The human brain confronts the same problem in everyday perception, extracting from its high-dimensional sensory inputs-30,000 auditory nerve fibers or 10(6) optic nerve fibers-a manageably small number of perceptually relevant features. Here we describe an approach to solving dimensionality reduction problems that uses easily measured local metric information to learn the underlying global geometry of a data set. Unlike classical techniques such as principal component analysis (PCA) and multidimensional scaling (MDS), our approach is capable of discovering the nonlinear degrees of freedom that underlie complex natural observations, such as human handwriting or images of a face under different viewing conditions. In contrast to previous algorithms for nonlinear dimensionality reduction, ours efficiently computes a globally optimal solution, and, for an important class of data manifolds, is guaranteed to converge asymptotically to the true structure.},
author = {Tenenbaum, J B and {De Silva}, V and Langford, J C},
doi = {10.1126/science.290.5500.2319},
institution = {Department of Psychology, Stanford University, Stanford, CA 94305, USA. jbt@psych.stanford.edu},
isbn = {159158230X},
issn = {00368075},
journal = {Science},
keywords = {algorithms,artificial intelligence,face,humans,mathematics,pattern recognition,visual,visual perception},
number = {5500},
pages = {2319--23},
pmid = {11125149},
publisher = {AAAS},
title = {{A global geometric framework for nonlinear dimensionality reduction.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/11125149},
volume = {290},
year = {2000}
}
@book{bishop2006pra,
abstract = {The dramatic growth in practical applications for machine learning over the last ten years has been accompanied by many important developments in the underlying algorithms and techniques. For example, Bayesian methods have grown from a specialist niche to become mainstream, while graphical models have emerged as a general framework for describing and applying probabilistic techniques. The practical applicability of Bayesian methods has been greatly enhanced by the development of a range of approximate inference algorithms such as variational Bayes and expectation propagation, while new models based on kernels have had a significant impact on both algorithms and applications. This completely new textbook reflects these recent developments while providing a comprehensive introduction to the fields of pattern recognition and machine learning. It is aimed at advanced undergraduates or first-year PhD students, as well as researchers and practitioners. No previous knowledge of pattern recognition or machine learning concepts is assumed. Familiarity with multivariate calculus and basic linear algebra is required, and some experience in the use of probabilities would be helpful though not essential as the book includes a self-contained introduction to basic probability theory. The book is suitable for courses on machine learning, statistics, computer science, signal processing, computer vision, data mining, and bioinformatics. Extensive support is provided for course instructors, including more than 400 exercises, graded according to difficulty. Example solutions for a subset of the exercises are available from the book web site, while solutions for the remainder can be obtained by instructors from the publisher. The book is supported by a great deal of additional material, and the reader is encouraged to visit the book web site for the latest information. A forthcoming companion volume will deal with practical aspects of pattern recognition and machine learning, and will include free software implementations of the key algorithms along with example data sets and demonstration programs. Christopher Bishop is Assistant Director at Microsoft Research Cambridge, and also holds a Chair in Computer Science at the University of Edinburgh. He is a Fellow of Darwin College Cambridge, and was recently elected Fellow of the Royal Academy of Engineering. The author's previous textbook "Neural Networks for Pattern Recognition" has been widely adopted.},
archivePrefix = {arXiv},
arxivId = {0-387-31073-8},
author = {Bishop, Christopher M CM Christopher M.},
booktitle = {Pattern Recognition},
doi = {10.1117/1.2819119},
eprint = {0-387-31073-8},
isbn = {978-0387310732},
issn = {10179909},
pages = {738},
pmid = {8943268},
publisher = {Springer New York.},
title = {{Pattern recognition and machine learning}},
url = {http://soic.iupui.edu/syllabi/semesters/4142/INFO{\_}B529{\_}Liu{\_}s.pdf{\%}5Cnhttp://www.library.wisc.edu/selectedtocs/bg0137.pdf},
volume = {4},
year = {2006}
}
@article{Yosinski2009,
author = {Yosinski, Jason and Coult, Nick and Paffenroth, Randy},
doi = {10.1117/12.826565},
journal = {Proceedings of SPIE},
pages = {74450O--74450O--11},
publisher = {Spie},
title = {{Network-centric angle only tracking}},
url = {http://link.aip.org/link/PSISDG/v7445/i1/p74450O/s1{\&}Agg=doi},
year = {2009}
}
@article{Eckart1936,
abstract = {Abstract  The mathematical problem of approximating one matrix by another of lower rank is closely related to the fundamental postulate of factor-theory. When formulated as a least-squares problem, the normal equations cannot be immediately written down, since the elements of the approximate matrix are not independent of one another. The solution of the problem is simplified by first expressing the matrices in a canonic form. It is found that the problem always has a solution which is usually unique. Several conclusions can be drawn from the form of this solution.A hypothetical interpretation of the canonic components of a score matrix is discussed.},
author = {Eckart, C and Young, G},
doi = {10.1007/BF02288367},
issn = {00333123},
journal = {Psychometrika},
pages = {211--218},
title = {{The approximation of one matrix by another of lower rank}},
volume = {1},
year = {1936}
}
@article{Safavian1997,
abstract = {A novel multiresolution algorithm for lossy gray-scale image compression is presented. High-quality low bit rate image compression is achieved first by segmenting an image into regions of different sizes based on perceptual variation in each region and then constructing a distinct code for each block by using the theory of projection pursuit (PP). Projection pursuit allows one to adaptively construct a better approximation for each block by optimally selecting basis functions. The process is stopped when the desired peak signal-to-noise ratio (PSNR) or bit rate (b/pixel) is achieved. At rates below 0.5 b/pixel, our algorithm shows superior performance, both in terms of PSNR and subjective image quality, over the Joint Photographers Expert Group (JPEG) algorithm, and comparable performance to the embedded zerotree wavelet (EZW) algorithm},
author = {Safavian, S.R. and Rabiee, H.R. and Fardanesh, M.},
doi = {10.1109/97.575551},
issn = {10709908},
journal = {IEEE Signal Processing Letters},
month = {may},
number = {5},
pages = {117--120},
title = {{Projection pursuit image compression with variable block size segmentation}},
url = {http://ieeexplore.ieee.org/xpl/freeabs{\_}all.jsp?arnumber=575551},
volume = {4},
year = {1997}
}
@unpublished{Liu2010,
abstract = {The Fourier transform is an useful tool to analyze the frequency components of the signal. However, if we take the Fourier transform over the whole time axis, we cannot tell at what instant a particular frequency rises. Short-time Fourier transform (STFT) uses a sliding window to nd spectrogram, which gives the information of both time and frequency. But still another problem exists: The length of window limits the resolution in frequency. Wavelet transform seems to be a solution to the problem above. Wavelet transforms are based on small wavelets with limited duration. The translated-version wavelets locate where we concern. Whereas the scaled-version wavelets allow us to analyze the signal in different scale.},
author = {Liu, Chun-Liu},
booktitle = {History},
pages = {1--72},
title = {{A Tutorial of the Wavelet Transform}},
year = {2010}
}
@article{Jin2004,
archivePrefix = {arXiv},
arxivId = {arXiv:math/0410072v1},
author = {Jin, Jiashun and Donoho, David},
doi = {10.1214/009053604000000265},
eprint = {0410072v1},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin, Donoho - 2004 - Higher criticism for detecting sparse heterogeneous mixtures.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {and phrases,combining many p-values,multiple comparsions,sparse nor-},
month = {jun},
number = {3},
pages = {962--994},
primaryClass = {arXiv:math},
title = {{Higher criticism for detecting sparse heterogeneous mixtures}},
url = {http://projecteuclid.org/Dienst/getRecord?id=euclid.aos/1085408492/},
volume = {32},
year = {2004}
}
@inproceedings{Cutler2000,
address = {Los Alamitos, CA, USA},
author = {Cutler, Ross and Davis, Larry S},
booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
doi = {http://doi.ieeecomputersociety.org/10.1109/34.868681},
issn = {0162-8828},
number = {8},
pages = {781--796},
publisher = {IEEE Computer Society},
title = {{Robust Real-Time Periodic Motion Detection, Analysis, and Applications}},
volume = {22},
year = {2000}
}
@article{Belkin2003,
author = {Belkin, Mikhail and Niyogi, Partha},
journal = {Computer},
pages = {1373--1396},
title = {{Laplacian Eigenmaps for Dimensionality Reduction and Data}},
volume = {1396},
year = {2003}
}
@article{Ng2011,
abstract = {In the image processing community, there have recently been many restoration and reconstruction problems that can be reformulated into linearly constrained convex programming models whose objective functions have separable structures. These favorable reformulations have promoted impressive applications of the alternating direction method (ADM) in the field of image processing. At each iteration, the computation of ADM is dominated by solving two subproblems exactly. However, in many restoration and reconstruction applications, it is either impossible or extremely expensive to obtain exact solutions of these ADM subproblems. This fact urges the development on inexact versions of ADM, which allow the generated ADM subproblems to be solved approximately subject to certain inexactness criteria. In this paper, we develop some truly implementable inexact ADMs whose inexactness criteria controlling the accuracy of the ADM subproblems are easily implementable. The convergence of the new inexact ADMs will be proved. Numerical results on several image processing problems will be given to illustrate the effectiveness of the proposed inexact ADMs.},
author = {Ng, MK and Wang, Fan and Yuan, Xiaoming},
doi = {10.1137/100807697},
issn = {1064-8275},
journal = {SIAM Journal on Scientific Computing},
pages = {1643--1668},
title = {{Inexact alternating direction methods for image recovery}},
url = {http://epubs.siam.org/doi/abs/10.1137/100807697},
volume = {33},
year = {2011}
}
@book{kohonen01,
author = {Kohonen, T},
edition = {Second},
publisher = {Springer-Verlag Berlin Heidelberg},
title = {{Self-Organizing Maps}},
year = {2001}
}
@article{Yosinski2008,
author = {Yosinski, Jason and Paffenroth, Randy},
doi = {10.1117/12.778039},
issn = {0277786X},
journal = {Proceedings of SPIE},
keywords = {distributed database,distributed target tracking,initiation,siap,two-phase commit},
pages = {696915--696915--12},
publisher = {Spie},
title = {{A distributed database view of network tracking systems}},
url = {http://link.aip.org/link/PSISDG/v6969/i1/p696915/s1{\&}Agg=doi},
year = {2008}
}
@article{Finner2007,
author = {Finner, Helmut and Dickhaus, Thorsten and Roters, Markus},
doi = {10.1214/009053607000000046},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Finner, Dickhaus, Roters - 2007 - Dependency and false discovery rate Asymptotics.pdf:pdf},
issn = {0090-5364},
journal = {The Annals of Statistics},
keywords = {13,2,and,and prds,and proofs can be,are mtp 2,asymptotic con-,for example,found in,in genetics,in view of testing,more formal descriptions of,multivariate total positivity of,order 2,positive,problems with some,regression dependency on subsets,ten thousand hypotheses as,these conditions,they appear},
month = {aug},
number = {4},
pages = {1432--1455},
title = {{Dependency and false discovery rate: Asymptotics}},
url = {http://projecteuclid.org/euclid.aos/1188405617},
volume = {35},
year = {2007}
}
@book{Kruskal1978,
abstract = {Outlines a set of techniques that enable a researcher to discuss the "hidden structure" of large data bases. These techniques use proximities, measures which indicate how similar or different objects are, to find a configuration of points which reflects the structure in the data.},
author = {Kruskal, Joseph B. and Wish, Myron},
isbn = {0803909403},
pages = {93},
publisher = {SAGE Publications},
title = {{Multidimensional Scaling, Issue 11}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=ZzmIPcEXPf0C{\&}pgis=1},
year = {1978}
}
@article{Garber2001,
author = {Garber, ME},
journal = {Proceedings of the  {\ldots}},
title = {{Diversity of gene expression in adenocarcinoma of the lung}},
url = {http://www.pnas.org/content/98/24/13784.short},
year = {2001}
}
@book{Glass1970,
author = {Glass, GV and Hopkins, KD},
title = {{Statistical methods in education and psychology}},
url = {http://www.statpower.net/Content/310/Introduction.pdf},
year = {1970}
}
@article{Karbasi2010,
author = {Karbasi, A and Oh, S},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Karbasi, Oh - 2010 - Ultrasound tomography calibration using structured matrix completion.pdf:pdf},
journal = {The 20th International Congress on Acoustics (No. EPFL-CONF-149265)},
title = {{Ultrasound tomography calibration using structured matrix completion}},
url = {http://infoscience.epfl.ch/record/149265},
year = {2010}
}
@article{Cucuringu2010,
author = {Cucuringu, Mihai and Lipman, Yaron and Singer, Amit},
journal = {ACM Transactions on Sensor Networks},
number = {3},
title = {{Sensor network localization by eigenvector synchronization over the Euclidean group}},
url = {http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:Sensor+network+localization+by+eigenvector+synchronization+over+the+Euclidean+group{\#}0},
volume = {8},
year = {2010}
}
@article{Witten2013,
author = {Witten, R and Candes, E},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Witten, Candes - 2013 - Randomized algorithms for low-rank matrix factorizations sharp performance bounds.pdf:pdf},
journal = {Algorithmica},
title = {{Randomized algorithms for low-rank matrix factorizations: sharp performance bounds}},
url = {http://link.springer.com/article/10.1007/s00453-014-9891-7},
year = {2013}
}
@article{Elton1997,
abstract = {In this article we have reviewed “Modern Portfolio Analysis” and outlined some important topics for further research. Issues discussed include the history and future of portfolio theory, the key inputs necessary to perform portfolio optimization, specific problems in applying portfolio theory to financial institutions, and the methods for evaluating how well portfolios are managed. Emphasis is placed on both the history of major concepts and where further research is needed in each of these areas.},
author = {Elton, EJ and Gruber, MJ},
doi = {10.1016/S0378-4266(97)00048-4},
issn = {03784266},
journal = {Journal of Banking {\&} Finance},
pages = {1743--1759},
title = {{Modern portfolio theory, 1950 to date}},
url = {http://www.sciencedirect.com/science/article/pii/S0378426697000484},
volume = {21},
year = {1997}
}
@article{Gower1982,
abstract = {A unified account is given of distance matrices in the Euclidean geometry of many points in many dimensions. The aim is to make some interesting and useful results accessible to applied scientists, including statisticians.},
author = {Gower, J C},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Gower - 1982 - Euclidean distance geometry.pdf:pdf},
journal = {Mathematical Scientist},
number = {1},
pages = {1--14},
title = {{Euclidean distance geometry}},
url = {http://convexoptimization.com/TOOLS/Gower2.pdf},
volume = {7},
year = {1982}
}
@article{Mercer1909,
abstract = {"... any continuous, symmetric, positive semi-definite kernel function K(x,y) can be expressed as a dot product in a high-dimensional space. ..." (Jstor)'09, http://rsta.royalsocietypublishing.org/content/209/441-458/415.full.pdf+html (PTRS)'10, and (wikip)'09.},
author = {Mercer, J},
journal = {Philosophical Transactions of the Royal Society},
pages = {415--446},
title = {{Functions of positive and negative type and their connection with the theory of integral equations}},
volume = {A 209},
year = {1909}
}
@article{Smith1982,
abstract = {The article reviews the book "Modern Portfolio Theory and Investment Analysis," by E.J. Elton and M.J. Gruber.},
author = {Smith, Keith V},
doi = {10.2307/2327857},
isbn = {00221082},
issn = {00221082},
journal = {Journal of Finance},
keywords = {BOOKS -- Reviews,ELTON, E. J.,GRUBER, M. J.,MODERN Portfolio Theory {\&} Investment Analysis (Boo,NONFICTION},
pages = {1317--1319},
pmid = {983466},
title = {{Modern Portfolio Theory and Investment Analysis}},
url = {http://www.lib.lsu.edu/apps/onoffcampus.php?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=bth{\&}AN=4656294{\&}site=ehost-live{\&}scope=site},
volume = {37},
year = {1982}
}
@misc{Tosi2009,
abstract = {Create high quality 2D plots by using Matplotlib productively Incremental introduction to Matplotlib, from the ground up to advanced levels Embed Matplotlib in GTK+, Qt, and wxWidgets applications as well as web sites to utilize them in Python applications Deploy Matplotlib in web applications and expose it on the Web using popular web frameworks such as Pylons and Django Get to grips with hands-on code and complete realistic case study examples along with highly informative plot screenshots},
author = {Tosi, Sandro},
booktitle = {Packt Publishing},
doi = {10.1016/S0031-9201(00)00141-2},
isbn = {9781847197900},
pages = {308},
title = {{Matplotlib for Python Developers}},
url = {http://www.amazon.com/Matplotlib-Python-Developers-Sandro-Tosi/dp/1847197906},
year = {2009}
}
@article{Rietta2006,
author = {Rietta, FS},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Rietta - 2006 - Application layer intrusion detection for SQL injection.pdf:pdf},
journal = {Proceedings of the 44th annual Southeast regional conference},
pages = {531--536},
title = {{Application layer intrusion detection for SQL injection}},
url = {http://dl.acm.org/citation.cfm?id=1185564},
year = {2006}
}
@article{Xiaolin2008,
author = {Xiaolin, Cui and Xiaobin, Tan and Yong, Zhang and Hongsheng, Xi},
doi = {10.1109/CSSE.2008.949},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xiaolin et al. - 2008 - A Markov Game Theory-Based Risk Assessment Model for Network Information System.pdf:pdf},
isbn = {978-0-7695-3336-0},
journal = {2008 International Conference on Computer Science and Software Engineering},
keywords = {- risk assessment,markov game theory,threat},
number = {2006},
pages = {1057--1061},
publisher = {Ieee},
title = {{A Markov Game Theory-Based Risk Assessment Model for Network Information System}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4722524},
year = {2008}
}
@article{Ng2002,
abstract = { We propose using coordinates-based mechanisms in a peer-to-peer architecture to predict Internet network distance (i.e. round-trip propagation and transmission delay). We study two mechanisms. The first is a previously proposed scheme, called the triangulated heuristic, which is based on relative coordinates that are simply the distances from a host to some special network nodes. We propose the second mechanism, called global network positioning (GNP), which is based on absolute coordinates computed from modeling the Internet as a geometric space. Since end hosts maintain their own coordinates, these approaches allow end hosts to compute their inter-host distances as soon as they discover each other. Moreover, coordinates are very efficient in summarizing inter-host distances, making these approaches very scalable. By performing experiments using measured Internet distance data, we show that both coordinates-based schemes are more accurate than the existing state of the art system IDMaps, and the GNP approach achieves the highest accuracy and robustness among them.},
author = {Ng, T.S.E. and Zhang, Hui Zhang Hui},
doi = {10.1109/INFCOM.2002.1019258},
isbn = {0-7803-7476-2},
issn = {0743-166X},
journal = {Proceedings.Twenty-First Annual Joint Conference of the IEEE Computer and Communications Societies},
title = {{Predicting Internet network distance with coordinates-based approaches}},
volume = {1},
year = {2002}
}
@article{donoho06co,
author = {Donoho, D L},
journal = {IEEE Trans. Inform. Theory},
month = {apr},
number = {4},
pages = {1289--1306},
title = {{Compressed Sensing}},
volume = {52},
year = {2006}
}
@article{Alfakih2000,
abstract = {Let G=(V,E,$\omega$) be an incomplete graph with node set V, edge set E, and nonnegative weights $\omega$ij's on the edges. Let each edge (vi,vj) be viewed as a rigid bar, of length $\omega$ij, which can rotate freely around its end nodes. A realization of a graph G is an assignment of coordinates, in some Euclidean space, to each node of G. In this paper, we consider the problem of determining whether or not a given realization of a graph G is rigid. We show that each realization of G can be epresented as a point in a compact convex set Image ; and that a generic realization of G is rigid if and only if its corresponding point is a vertex of $\Omega$, i.e., an extreme point with full-dimensional normal cone.},
author = {Alfakih, AY},
doi = {10.1016/S0024-3795(00)00066-5},
issn = {00243795},
journal = {Linear Algebra and Its Applications},
pages = {149--165},
title = {{Graph rigidity via Euclidean distance matrices}},
url = {http://www.sciencedirect.com/science/article/pii/S0024379500000665},
volume = {310},
year = {2000}
}
@article{Abdi2007,
author = {Abdi, H},
title = {{Bonferroni and {\v{S}}id{\'{a}}k corrections for multiple comparisons.” In NJ Salkind (ed.). Encyclopedia of Measurement and Statistics. Thousand Oaks, CA: Sage}},
url = {http://scholar.google.com/scholar?q=Bonferroni+and+{\v{S}}id{\'{a}}k+corrections+for+multiple+comparisons{\&}btnG={\&}hl=en{\&}as{\_}sdt=0,22{\#}0},
year = {2007}
}
@article{Dattorro2008,
author = {Dattorro, Jon},
doi = {10.1016/j.laa.2007.12.008},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dattorro - 2008 - Equality relating Euclidean distance cone to positive semidefinite cone.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
keywords = {We know that the cone of Euclidean distance matric,distance matrix},
month = {jun},
number = {11-12},
pages = {2597--2600},
title = {{Equality relating Euclidean distance cone to positive semidefinite cone}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0024379507005666},
volume = {428},
year = {2008}
}
@article{Heidemann2008,
abstract = {Prior measurement studies of the Internet have explored traffic and topology, but have largely ignored edge hosts. While the number of Internet hosts is very large, and many are hidden behind firewalls or in private address space, there is much to be learned from examining the population of visible hosts, those with public unicast addresses that respond to messages. In this paper we introduce two new approaches to explore the visible Internet. Applying statistical population sampling, we use censuses to walk the entire Internet address space, and surveys to probe frequently a fraction of that space. We then use these tools to evaluate address usage, where we find that only 3.6{\%} of allocated addresses are actually occupied by visible hosts, and that occupancy is unevenly distributed, with a quarter of responsive /24 address blocks (subnets) less than 5{\%} full, and only 9{\%} of blocks more than half full. We show about 34 million addresses are very stable and visible to our probes (about 16{\%} of responsive addresses), and we project from this up to 60 million stable Internet-accessible computers. The remainder of allocated addresses are used intermittently, with a median occupancy of 81 minutes. Finally, we show that many firewalls are visible, measuring significant diversity in the distribution of firewalled block size. To our knowledge, we are the first to take a census of edge hosts in the visible Internet since 1982, to evaluate the accuracy of active probing for address census and survey, and to quantify these aspects of the Internet.},
author = {Heidemann, John and Pradkin, Yuri and Govindan, Ramesh and Papadopoulos, Christos and Bartlett, Genevieve and Bannister, Joseph},
doi = {10.1145/1452520.1452542},
isbn = {9781605583341},
journal = {Proceedings of the ACM Internet Measurement Conference},
keywords = {actively probe internet,firewalls,internet address allocation,ipv4,par,viruses engage massively},
pages = {169},
title = {{Census and Survey of the Visible Internet}},
url = {http://portal.acm.org/citation.cfm?doid=1452520.1452542},
year = {2008}
}
@misc{SonyAttack,
annote = {undefined},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Sony Pictures confirms LulzSec hacker attack, FBI probe - latimes.com.html:html},
title = {{Sony Pictures confirms LulzSec hacker attack, FBI probe - latimes.com}},
url = {http://latimesblogs.latimes.com/technology/2011/06/sony-lulzsec-hackers.html},
urldate = {2011-06-21}
}
@article{Wang2011,
author = {Wang, Jianzhong},
doi = {10.1007/978-3-642-27497-8_9},
isbn = {978-3-642-27496-1},
journal = {Geometric Structure of High-Dimensional Data and  {\ldots}},
pages = {181--202},
title = {{Maximum Variance Unfolding}},
url = {http://link.springer.com/chapter/10.1007/978-3-642-27497-8{\_}9},
year = {2012}
}
@book{Krislock2012,
author = {Krislock, N and Wolkowicz, H},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krislock, Wolkowicz - 2012 - Euclidean distance matrices and applications.pdf:pdf},
title = {{Euclidean distance matrices and applications}},
url = {http://link.springer.com/chapter/10.1007/978-1-4614-0769-0{\_}30},
year = {2012}
}
@incollection{Smith1997a,
abstract = {Although complex numbers are fundamentally disconnected from our reality, they can be used to solve science and engineering problems in two ways. First, the parameters from a real world problem can be substituted into a complex form, as presented in the last chapter. The second method is much more elegant and powerful, a way of making the complex numbers mathematically equivalent to the physical problem. This approach leads to the complex Fourier transform, a more sophisticated version of the real Fourier transform discussed in Chapter 8. The complex Fourier transform is important in itself, but also as a stepping stone to more powerful complex techniques, such as the Laplace and z-transforms. These complex transforms are the foundation of theoretical DSP.},
author = {Smith, Steven W.},
booktitle = {The Scientist and Engineer's Guide to Digital Signal Processing},
doi = {10.1016/B978-0-7506-7444-7/50068-6},
isbn = {9780750674447},
pages = {567--580},
title = {{The Complex Fourier Transform}},
year = {1997}
}
@incollection{Kantardzic2011,
abstract = {This chapter contains sections titled: * Graph Mining * Temporal Data Mining * Spatial Data Mining (SDM) * Distributed Data Mining (DDM) * Correlation Does Not Imply Causality * Privacy, Security, and Legal Aspects of Data Mining * Review Questions and Problems * References for Further Study},
author = {Kantardzic, Mehmed},
booktitle = {Data Mining},
doi = {10.1002/9781118029145.ch12},
isbn = {9781118029145},
keywords = {DBSCAN clustering,data mining advances,privacy protection},
pages = {328--384},
title = {{Advances in Data Mining}},
url = {http://dx.doi.org/10.1002/9781118029145.ch12},
year = {2011}
}
@article{ringberg2007a,
abstract = {Detecting anomalous traffic is a crucial part of managing IP networks. In recent years, network-wide anomaly detection based on Principal Component Analysis (PCA) has emerged as a powerful method for detecting a wide variety of anomalies. We show that tuning PCA to operate effectively in practice is difficult and requires more robust techniques than have been presented thus far. We analyze a week of network-wide traffic measurements from two IP backbones (Abilene and Geant) across three different traffic aggregations (ingress routers, OD flows, and input links), and conduct a detailed inspection of the feature time series for each suspected anomaly. Our study identifies and evaluates four main challenges of using PCA to detect traffic anomalies: (i) the false positive rate is very sensitive to small differences in the number of principal components in the normal subspace, (ii) the effectiveness of PCA is sensitive to the level of aggregation of the traffic measurements, (iii) a large anomaly may in advertently pollute the normal subspace, (iv) correctly identifying which flow triggered the anomaly detector is an inherently challenging problem.},
author = {Ringberg, Haakon and Soule, Augustin and Rexford, Jennifer and Diot, Christophe},
doi = {10.1145/1254882.1254895},
isbn = {9781595936394},
issn = {01635999},
journal = {Proceedings of the 2007 ACM SIGMETRICS international conference on Measurement and modeling of computer systems SIGMETRICS 07},
keywords = {network traffic analysis,principal component analysis},
pages = {109},
title = {{Sensitivity of PCA for traffic anomaly detection}},
volume = {35},
year = {2007}
}
@article{Candes2006,
author = {Cand{\`{e}}s, E.J. and Romberg, Justin and Tao, Terence and Candes, E},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand{\`{e}}s, Romberg, Tao - 2006 - Robust uncertainty principles Exact signal reconstruction from highly incomplete frequency information.pdf:pdf},
journal = {Information Theory, IEEE Transactions on},
month = {feb},
number = {2},
pages = {489--509},
publisher = {IEEE},
title = {{Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1580791 http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=1580791},
volume = {52},
year = {2006}
}
@misc{Park1991,
abstract = {There have been several recent studies concerning feedforward networks and the problem of approximating arbitrary functionals of a finite number of real variables. Some of these studies deal with cases in which the hidden-layer nonlinearity is not a sigmoid. This was motivated by successful applications of feedforward networks with nonsigmoidal hidden-layer units. This paper reports on a related study of radial-basis-function (RBF) networks, and it is proved that RBF networks having one hidden layer are capable of universal approximation. Here the emphasis is on the case of typical RBF networks, and the results show that a certain class of RBF networks with the same smoothing factor in each kernel node is broad enough for universal approximation.},
author = {Park, J. and Sandberg, I. W.},
booktitle = {Neural Computation},
doi = {10.1162/neco.1991.3.2.246},
issn = {0899-7667},
pages = {246--257},
title = {{Universal Approximation Using Radial-Basis-Function Networks}},
volume = {3},
year = {1991}
}
@book{BP99:ch4,
address = {Boston, London},
annote = {From Duplicate 1 ( 


Design and analysis of modern tracking systems


- Blackman, S; Popoli, R )




From Duplicate 1 ( 


Design and Analysis of Modern Tracking Systems


- Blackman, S; Popoli, R )








From Duplicate 2 ( 


Design and analysis of modern tracking systems


- Blackman, S; Popoli, R )



Chapter 4







From Duplicate 2 ( 


Design and analysis of modern tracking systems


- Blackman, S; Popoli, R )



Chapter 4},
author = {Blackman, S and Popoli, R},
publisher = {Artech House},
title = {{Design and analysis of modern tracking systems}},
year = {1999}
}
@misc{Cai2008,
abstract = {. One of the key steps in compressed sensing is to solve the basis pursuit problem minu∈R n{\{}�u�1: Au = f{\}}. Bregman iteration was very successfully used to solve this problem in [40]. Also, a simple and fast iterative algorithm based on linearized Bregman iteration was proposed in [40], which is described in detail with numerical simulations in [35]. A convergence analysis of the smoothed version of this algorithm was given in [11]. The purpose of this paper is to prove that the linearized Bregman iteration proposed in [40] for the basis pursuit problem indeed converges. 1.},
author = {Cai, Jian-feng and Osher, Stanley and Shen, Zuowei},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai, Osher, Shen - 2008 - Convergence of the Linearized Bregman Iteration for ℓ1-norm Minimization.pdf:pdf},
title = {{Convergence of the Linearized Bregman Iteration for ℓ1-norm Minimization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.139.8779},
year = {2008}
}
@book{IT2002,
abstract = {Timmerman reviews Principal Component Analysis (2nd Ed.). I. T. Jolliffe},
author = {{I T}, Jolliffe},
booktitle = {Journal of the American Statistical Association},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/I T - 2002 - Principal Component Analysis,2nd ed.html:html},
issn = {01621459},
keywords = {principal component analysis,statistical theory methods},
pages = {487},
title = {{"Principal Component Analysis,2nd ed"}},
volume = {98},
year = {2002}
}
@article{Weinberger2005,
author = {Weinberger, KQ and Packer, BD and Saul, LK},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Weinberger, Packer, Saul - 2005 - Nonlinear dimensionality reduction by semidefinite programming and kernel matrix factorization.pdf:pdf},
journal = {Proceedings of the tenth  {\ldots}},
title = {{Nonlinear dimensionality reduction by semidefinite programming and kernel matrix factorization}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.221.8829{\&}rep=rep1{\&}type=pdf{\#}page=390},
year = {2005}
}
@article{Lee2001,
author = {Lee, Wenke and Xiang, D},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Xiang - 2001 - Information-theoretic measures for anomaly detection.pdf:pdf},
journal = {Security and Privacy, 2001. S$\backslash${\&}P 2001. Proceedings. 2001 IEEE Symposium on},
pages = {130--143},
title = {{Information-theoretic measures for anomaly detection}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=924294},
year = {2001}
}
@article{GSC09,
author = {Gubner, J A and Scharf, L L and Chong, E K F},
journal = {IEEE International Conf on Acopustics},
month = {apr},
title = {{Robust Threshold Selection to Guarantee Exponential Error Decay Using an All-Purpose Fusion Rule for Wireless Sensor Networks}},
year = {2009}
}
@article{harary1976metric,
author = {Harary, Frank and Melter, R A},
journal = {Ars Combin},
number = {191-195},
pages = {1},
title = {{On the metric dimension of a graph}},
volume = {2},
year = {1976}
}
@book{Ledoux2005,
author = {Ledoux, M},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ledoux - 2001 - The concentration of measure phenomenon.pdf:pdf},
title = {{The concentration of measure phenomenon}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=rRKChz4Om6gC{\&}oi=fnd{\&}pg=PR7{\&}dq=The+concentration+of+measure+phenomena{\&}ots=VJnYcFnyaU{\&}sig=GwvbtpJhuX9xHOzrQ8TQ4zw{\_}LG0 http://books.google.com/books?hl=en{\&}lr={\&}id=rRKChz4Om6gC{\&}oi=fnd{\&}pg=PR7{\&}dq=The+concentration+of+me},
year = {2001}
}
@article{ODonoghue2013,
archivePrefix = {arXiv},
arxivId = {1312.3039},
author = {O'Donoghue, Brendan and Chu, Eric and Parikh, Neal and Boyd, Stephen},
eprint = {1312.3039},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/O'Donoghue et al. - 2013 - Operator Splitting for Conic Optimization via Homogeneous Self-Dual Embedding.pdf:pdf},
month = {dec},
title = {{Operator Splitting for Conic Optimization via Homogeneous Self-Dual Embedding}},
url = {http://arxiv.org/abs/1312.3039},
year = {2013}
}
@article{Paffenroth2012,
annote = {From Duplicate 2 (Space-time signal processing for distributed pattern detection in sensor networks - Paffenroth, Randy C; Toit, Philip Du; Nong, Ryan; Scharf, Louis L; Jayasumana, Anura P; Bandara, Vidarshana; Du Toit, Philip C; Banadara, Vidarshana)

From Duplicate 2 ( 



























































Space-time signal processing for distributed pattern detection in sensor networks



























































- Paffenroth, Randy; Toit, Philip Du; Nong, Ryan; Scharf, Louis L; Jayasumana, Anura; Bandara, Vidarshana )














































From Duplicate 2 ( 



























































Space-time signal processing for distributed pattern detection in sensor networks



























































- Paffenroth, Randy; Toit, Philip Du; Nong, Ryan; Scharf, Louis L; Jayasumana, Anura; Bandara, Vidarshana )















},
author = {Paffenroth, Randy C and Toit, Philip Du and Nong, Ryan and Scharf, Louis L and Jayasumana, Anura P and Bandara, Vidarshana and {Du Toit}, Philip C and Banadara, Vidarshana and Scharf, Louis L and Jayasumana, Anura P and Banadara, Vidarshana and Nong, Ryan},
doi = {10.1117/12.919711},
journal = {IEEE Journal of Selected Topics in Signal Processing},
number = {1},
pages = {38--49},
title = {{Space-time signal processing for distributed pattern detection in sensor networks}},
url = {+ http://dx.doi.org/10.1117/12.919711},
volume = {7},
year = {2013}
}
@article{Gao2008,
abstract = {We introduce a robust probabilistic L1-PCA model in which the conventional gaussian distribution for the noise in the observed data was replaced by the Laplacian distribution (or L1 distribution). Due to the heavy tail characteristics of the L1 distribution, the proposed model is supposed to be more robust against data outliers. In this letter, we demonstrate how a variational approximation scheme enables effective inference of key parameters in the probabilistic L1-PCA model. As the L1 density can be expanded as a superposition of infinite number of gaussian densities, we express the L1-PCA model as a marginalized model over the superpositions. By doing so, a tractable Bayesian inference can be achieved based on the variational expectation-maximization-type algorithm.},
author = {Gao, Junbin},
doi = {10.1162/neco.2007.11-06-397},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Artificial Intelligence,Bayes Theorem,Data Interpretation, Statistical,Humans,Neural Networks (Computer),Normal Distribution,Principal Component Analysis},
month = {feb},
number = {2},
pages = {555--72},
pmid = {18045015},
title = {{Robust L1 principal component analysis and its Bayesian variational inference.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20400256},
volume = {20},
year = {2008}
}
@book{Aggarwal2010a,
abstract = {Graph pattern mining. In this chapter, we first examine the existing frequent subgraph mining algorithms and discuss their computational bottle- neck. Then we introduce recent studies on mining significant and representative subgraph patterns. These new mining algorithms represent the state-of-the-art graph mining techniques: they not only avoid the exponential size of mining result, but also improve the applicability of graph patterns significantly},
author = {Aggarwal, Cc and Wang, Haixun},
booktitle = {Database},
doi = {10.1007/978-1-4419-6045-0},
isbn = {978-1-4419-6044-3},
issn = {00283908},
pages = {487--513},
pmid = {17888460},
title = {{Managing and mining graph data}},
url = {http://www.springerlink.com/index/10.1007/978-1-4419-6045-0{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=Ox39uLyYh-wC{\&}oi=fnd{\&}pg=PR1{\&}dq=Managing+and+Mining+Graph+Data{\&}ots=JREM6{\_}9ZRm{\&}sig=Jxc2GIshluOnne2BS2-aji48MbU{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=Ox39uLyYh-wC{\&}oi=fnd{\&}pg=PR1{\&}dq=Managing+and+mining+graph+data{\&}ots=JREM6{\_}9ZRu{\&}sig=HGXxe8SbeBX2Ec0bp1TQ1oEWvcc{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=Ox39uLyYh-wC{\&}oi=fnd{\&}pg=PR1{\&}dq=Managing+and+mining+graph+data{\&}ots=JREM6{\_}9{\_}Ot{\&}sig=Rp3Imd6NZA4z},
volume = {40},
year = {2010}
}
@article{Fabozzi2002,
abstract = {Fifty years have passed since the publication of Harry Markowitz's article on portfolio selection, setting forth the ground-breaking concepts that have come to form the foundation of what is now popularly referred to as Modern Portfolio Theory (MPT). In this article the authors briefly explain the theory underlying MPT and using illustrations highlight the application of MPT to the current practice of asset management and portfolio construction. The authors also survey most of the relevant research that has directly or indirectly been either an outcome of MPT or has contributed to the implementation of MPT.},
author = {Fabozzi, FJ and Gupta, Francis and Markowitz, HM},
doi = {10.3905/joi.2002.319510},
issn = {1068-0896},
journal = {The Journal of Investing},
pages = {7--22},
title = {{The legacy of modern portfolio theory}},
url = {http://www.iijournals.com/doi/abs/10.3905/joi.2002.319510},
volume = {11},
year = {2002}
}
@article{Bandara2013,
author = {Bandara, V. and Scharf, L. and Paffenroth, R. and Jayasumana, A. and DuToit, P.},
journal = {In Review, IEEE Journal of Knowledge Data Engineering},
title = {{Empirical Recovery Regions of Robust PCA}},
year = {2013}
}
@article{Clark2014,
author = {Clark, D and Berson, T and Lin, HS},
journal = {National Academies Press},
title = {{At the Nexus of Cybersecurity and Public Policy:: Some Basic Concepts and Issues}},
url = {http://scholar.google.com/scholar?hl=en{\&}q=At+the+Nexus+of+Cybersecurity+and+Public+Policy:+Some+Basic+Concepts+and+Issues{\&}btnG={\&}as{\_}sdt=1,22{\&}as{\_}sdtp={\#}0 http://scholar.google.com/scholar?hl=en{\&}btnG=Search{\&}q=intitle:At+the+Nexus+of+Cybersecurity+and+Public+Policy::+Some+Basic+Concepts+and+Issues{\#}0},
year = {2014}
}
@book{Chun2006,
abstract = {Published September 18, 2006, 1120 pages. SUMMARY: Praise for "Core Python Programming ""The long-awaited second edition of Wesley Chun's "Core Python Programming" proves to be well worth the wait-its deep and broad coverage and useful exercises will help readers learn and practice good Python."-Alex Martelli, author of "Python in a Nutshell" and editor of "Python Cookbook""There has been lot of good buzz around Wesley Chun's "Core Python Programming." It turns out that all the buzz is well earned. I think this is the best book currently available for learning Python. I would recommend Chun's book over "Learning Python" (O'Reilly), "Programming Python" (O'Reilly), or "The Quick Python Book" (Manning)."-David Mertz, Ph.D., IBM DeveloperWorks(R)"I have been doing a lot of research on Python for the past year and have seen a number of positive reviews of your book. The sentiment expressed confirms the opinion that "Core Python Programming" is now considered the standard introductory text."-Richard Ozaki, Lockheed Martin"Finally, a book good enough to be both a textbook and a reference on the Python language now exists."-Michael Baxter, "Linux Journal""Very well written. It is the clearest, friendliest book I have come across yet for explaining Python, and putting it in a wider context. It does not presume a large amount of other experience. It does go into some important Python topics carefully and in depth. Unlike too many beginner books, it never condescends or tortures the reader with childish hide-and-seek prose games. It sticks to gaining a solid grasp of Python syntax and structure." -http: //python.org bookstore Web site" If I could only own one Python book, it would be "Core PythonProgramming" by Wesley Chun. This book manages to cover more topics in more depth than Learning Python but includes it all in one book that also more than adequately covers the core language. If you are in the market for just one book about Python, I recommend this book. You will enjoy reading it, including its wry programmer's wit. More importantly, you will learn Python. Even more importantly, you will find it invaluable in helping you in your day-to-day Python programming life. Well done, Mr. Chun!"-Ron Stephens, Python Learning Foundation"I think the best language for beginners is Python, without a doubt. My favorite book is "Core Python Programming.""-s003apr, MP3Car.com Forums"Personally, I really like Python. It's simple to learn, completely intuitive, amazingly flexible, and pretty darned fast. Python has only just started to claim mindshare in the Windows world, but look for it to start gaining lots of support as people discover it. To learn Python, I'd start with "Core Python Programming" by Wesley Chun."-Bill Boswell, MCSE, Microsoft Certified Professional Magazine Online"If you learn well from books, I suggest "Core Python Programming." It is by far the best I've found. I'm a Python newbie as well and in three months time I've been able to implement Python in projects at work (automating MSOffice, SQL DB stuff, etc.)."-ptonman, Dev Shed Forums"Python is simply a beautiful language. It's easy to learn, it's cross-platform, and it works. It has achieved many of the technical goals that Java strives for. A one-sentence description of Python would be: 'All other languages appear to have evolved over time-but Python was designed.' And it wasdesigned well. Unfortunately, there aren't a large number of books for Python. The best one I've run across so far is "Core Python Programming.""-Chris Timmons, C. R. Timmons Consulting"If you like the Prentice Hall Core series, another good full-blown treatment to consider would be "Core Python Programming." It addresses in elaborate concrete detail many practical topics that get little, if any, coverage in other books."-Mitchell L Model, MLM Consulting""Core Python Programming" is an amazingly easy read! The liberal use of examples helps clarify some of the more subtle points of the language. And the comparisons to languages with which I'm already familiar (C/C++/Java) get you programming in record speed."-Michael Santos, Ph.D., Green Hills SoftwareThe Complete Developer's Guide to Python-Fully Updated for Python 2.5New to Python? The definitive guide to Python development for experienced programmersCovers core language features thoroughly, including those found in the latest Python releasesLearn advanced topics such as regular expressions, networking, multithreading, GUI, and Web/CGIIncludes brand-new chapters on database, Internet, Jython, and COM Client programmingPresents hundreds of code samples and practical exercises to strengthen your Python skillsPython is an agile, robust, expressive, fully object-oriented, extensible, and scalable programming language. It combines the power of compiled languages with the simplicity and rapid development of scripting languages. In "Core Python Programming, Second Edition," leading Python developer and trainer Wesley Chun helps you learn Python quickly and comprehensively so that you can immediately succeed with anyPython project.Using practical code examples, Chun introduces all the fundamentals of Python programming: syntax, objects and memory management, data types, operators, files and I/O, functions, generators, error handling and exceptions, loops, iterators, functional programming, object-oriented programming and more. After you learn the core fundamentals of Python, he shows you what you can do with your new skills, delving into advanced topics, such as regular expressions, networking programming with sockets, multithreading, GUI development, Web/CGI programming and extending Python in C.This edition reflects major enhancements in the Python 2.x series, including 2.5 as well as capabilities set for future versions. It contains new chapters on database and Internet client programming, plus coverage of many new topics, including new-style classes, Java and Jython, Microsoft Office (Win32 COM Client) programming, and much more.Learn professional Python style, best practices, and good programming habitsGain a deep understanding of Python's objects and memory model as well as its OOP features, including those found in Python's new-style classesBuild more effective Web, CGI, Internet, and network and other client/server applicationsLearn how to develop your own GUI applications using Tkinter and other toolkits available for PythonImprove the performance of your Python applications by writing extensions in C and other languages, or enhance I/O-bound applications by using multithreadingLearn about Python's database API and how to use a variety of database systems with Python, including MySQL, Postgres, and SQLite"Core Python Programming" deliversSystematic, expert coverage of Python'score featuresPowerful insights for developing complex applicationsEasy-to-use tables and charts detailing Python modules, operators, functions, and methodsDozens of professional-quality code examples, from quick snippets to full-fledged applications},
author = {Chun, WJ},
booktitle = {Review Literature And Arts Of The Americas},
doi = {10.1063/1.454032},
isbn = {0130260363},
pages = {0--13},
title = {{Core python programming}},
url = {http://portal.acm.org/citation.cfm?id=1177267{\&}dl=},
year = {2006}
}
@article{Shen2007,
author = {Shen, Dan and Chen, Genshe and Cruz, Jose B. and Kwan, Chiman and Kruger, Martin},
doi = {10.1109/AERO.2007.352800},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Shen et al. - 2007 - An Adaptive Markov Game Model for Threat Intent Inference.pdf:pdf},
isbn = {1-4244-0524-6},
journal = {2007 IEEE Aerospace Conference},
number = {February},
pages = {1--13},
publisher = {Ieee},
title = {{An Adaptive Markov Game Model for Threat Intent Inference}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4161613},
year = {2007}
}
@article{Mitchell2006,
abstract = {Over the past 50 years the study of Machine Learning has grown from the efforts of a handful of computer en- gineers exploring whether computers could learn to play games, and a field of Statistics that largely ignored computational considerations, to a broad discipline that has produced fundamental statistical-computational theories of learning processes, has designed learning algorithms that are routinely used in commercial sys- tems for speech recognition, computer vision, and a variety of other tasks, and has spun off an industry in data mining to discover hidden regularities in the growing volumes of online data. This document provides a brief and personal view of the discipline that has emerged as Machine Learning, the fundamental questions it addresses, its relationship to other sciences and society, and where it might be headed.},
author = {Mitchell, Tom M},
doi = {10.1080/026404199365326},
isbn = {0070428077},
issn = {0264-0414},
journal = {Machine Learning},
keywords = {machine learning},
pages = {1--7},
pmid = {10622353},
title = {{The Discipline of Machine Learning}},
url = {http://www-cgi.cs.cmu.edu/{~}tom/pubs/MachineLearningTR.pdf},
volume = {17},
year = {2006}
}
@article{Rossum2010,
abstract = {If you do muchwork on computers, eventually you find that theres some task youd like to automate. For example, you may wish to perform a search-and-replace over a large number of text files, or rename and rearrange a bunch of photo files in a complicated way. Perhaps youd like to write a small custom database, or a specialized GUI application, or a simple game. If youre a professional software developer, you may have to work with several C/C++/Java libraries but find the usual write/compile/test/re-compile cycle is too slow. Perhaps youre writing a test suite for such a library and find writing the testing code a tedious task. Or maybe youve written a program that could use an extension language, and you dont want to design and implement a whole new language for your application.},
author = {Rossum, Guido Van and Drake, Fred L},
doi = {10.1111/j.1094-348X.2008.00203_7.x},
isbn = {9789004155008},
journal = {History},
pages = {1--122},
title = {{Python Tutorial}},
url = {http://docs.python.org/tutorial/},
volume = {42},
year = {2010}
}
@article{Patcha2007,
author = {Patcha, Animesh and Park, Jung-Min},
doi = {10.1016/j.comnet.2007.02.001},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Patcha, Park - 2007 - An overview of anomaly detection techniques Existing solutions and latest technological trends.pdf:pdf},
issn = {13891286},
journal = {Computer Networks},
month = {aug},
number = {12},
pages = {3448--3470},
title = {{An overview of anomaly detection techniques: Existing solutions and latest technological trends}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S138912860700062X},
volume = {51},
year = {2007}
}
@article{Moore2001,
abstract = {K-means is the most famous clustering algorithm. In this tutorial we review just what it is that clustering is trying to achieve, and we show the detailed reason that the k-means approach is cleverly optimizing something very meaningful. Oh yes, and we'll tell you (and show you) what the k-means algorithm actually does. You'll also learn about another famous class of clusterers: hierarchical methods (much beloved in the life sciences). Phrases like "Hierarchical Agglomerative Clustering" and "Single Linkage Clustering" will be bandied about.},
author = {Moore, A},
journal = {Statistical Data Mining Tutorials},
pages = {1--24},
title = {{K-means and Hierarchical Clustering}},
url = {http://www.cs.cmu.edu/afs/cs/user/awm/web/tutorials/kmeans11.pdf},
year = {2001}
}
@article{Li1990,
author = {Li, Wentian},
doi = {10.1007/BF01025996},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Li - 1990 - Mutual information functions versus correlation functions.pdf:pdf},
issn = {0022-4715},
journal = {Journal of Statistical Physics},
keywords = {correlation functions,linear and general dependence,mutual information function,symbolic noise},
month = {sep},
number = {5-6},
pages = {823--837},
title = {{Mutual information functions versus correlation functions}},
url = {http://link.springer.com/10.1007/BF01025996},
volume = {60},
year = {1990}
}
@article{Hoffmann2007a,
author = {Hoffmann, H},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hoffmann - 2007 - Kernel PCA for novelty detection.pdf:pdf},
journal = {Pattern Recognition},
number = {3},
pages = {863--874},
title = {{Kernel PCA for novelty detection}},
url = {http://www.sciencedirect.com/science/article/pii/S0031320306003414},
volume = {40},
year = {2007}
}
@article{ds502,
abstract = {File swarming (or file sharing) is one of the most important applications in P2P networks. In this paper, we propose a stochastic framework to analyze a file-swarming system under realistic setting: constraints in upload/download capacity, collaboration among peers and incentive for chunk exchange. We first extend the results in the coupon system [L. Massoulie, M. Vojnovic, Coupon replication systems, in: Proc. ACM SIGMETRICS, Banff, Alberta, Canada, 2005] by providing a tighter performance bound. Then we generalize the coupon system by considering peers with limited upload and download capacity. We illustrate the last-piece problem and show the effectiveness of using forward error-correction (FEC) code and/or multiple requests to improve the performance. Lastly, we propose a framework to analyze an incentive-based file-swarming system. The stochastic framework we propose can serve as a basis for other researchers to analyze and design more advanced features of file-swarming systems. {\textcopyright} 2007 Elsevier Ltd. All rights reserved.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Lin, Minghong and Fan, Bin and Lui, John C S and Chiu, Dah Ming},
doi = {10.1016/j.peva.2007.06.006},
eprint = {arXiv:1011.1669v3},
isbn = {9780387781884},
issn = {01665316},
journal = {Performance Evaluation},
keywords = {BitTorrent,P2P file sharing,Performance modeling},
number = {9-12},
pages = {856--875},
pmid = {10911016},
publisher = {Springer New York},
series = {Springer Texts in Statistics},
title = {{Stochastic analysis of file-swarming systems}},
url = {https://books.google.com/books?id=qcI{\_}AAAAQBAJ http://books.google.com/books?id=9tv0taI8l6YC},
volume = {64},
year = {2007}
}
@book{boslaugh2009a,
abstract = {Need to learn statistics as part of your job, or want some help passing a statistics course? Statistics in a Nutshell is a clear and concise introduction and reference that's perfect for anyone with no previous background in the subject. This book gives you a solid understanding of statistics without being too simple, yet without the numbing complexity of most college texts. You get a firm grasp of the fundamentals and a hands-on understanding of how to apply them before moving on to the more advanced material that follows. Each chapter presents you with easy-to-follow descriptions illustrated by graphics, formulas, and plenty of solved examples. Before you know it, you'll learn to apply statistical reasoning and statistical techniques, from basic concepts of probability and hypothesis testing to multivariate analysis. Organized into four distinct sections, Statistics in a Nutshell offers you:Introductory material: Different ways to think about statistics Basic concepts of measurement and probability theoryData management for statistical analysis Research design and experimental design How to critique statistics presented by others Basic inferential statistics: Basic concepts of inferential statistics The concept of correlation, when it is and is not an appropriate measure of association Dichotomous and categorical data The distinction between parametric and nonparametric statistics Advanced inferential techniques: The General Linear Model Analysis of Variance (ANOVA) and MANOVA Multiple linear regression Specialized techniques: Business and quality improvement statistics Medical and public health statistics Educational and psychological statistics Unlike many introductory books on the subject, Statistics in a Nutshell doesn't omit important material in an effort to dumb it down. And this book is far more practical than most college texts, which tend to over-emphasize calculation without teaching you when and how to apply different statistical tests. With Statistics in a Nutshell, you learn how to perform most common statistical analyses, and understand statistical techniques presented in research articles. If you need to know how to use a wide range of statistical techniques without getting in over your head, this is the book you want.},
author = {Boslaugh, Sarah and Watters, Dr. Paul Andrew},
isbn = {1449397816},
pages = {480},
publisher = {O'Reilly Media, Inc.},
title = {{Statistics in a Nutshell: A Desktop Quick Reference (Google eBook)}},
url = {http://books.google.com/books?id=ZnhgO65Pyl4C{\&}pgis=1},
year = {2009}
}
@article{Erdos1960,
abstract = {In this work, we study a family of random geometric graphs on hyperbolic spaces. In this setting, N points are chosen randomly on a hyperbolic space and any two of them are joined by an edge with probability that depends on their hyperbolic distance, independently of every other pair. In particular, when the positions of the points have been fixed, the distribution over the set of graphs on these points is the Boltzmann distribution, where the Hamiltonian is given by the sum of weighted indicator functions for each pair of points, with the weight being proportional to a real parameter $\backslash$beta{\textgreater}0 (interpreted as the inverse temperature) as well as to the hyperbolic distance between the corresponding points. This class of random graphs was introduced by Krioukov et al. We provide a rigorous analysis of aspects of this model and its dependence on the parameter $\backslash$beta, verifying some of their observations. We show that a phase transition occurs around $\backslash$beta =1. More specifically, we show that when $\backslash$beta {\textgreater} 1 the degree of a typical vertex is bounded in probability (in fact it follows a distribution which for large values exhibits a power-law tail whose exponent depends only on the curvature of the space), whereas for $\backslash$beta {\textless}1 the degree is a random variable whose expected value grows polynomially in N. When $\backslash$beta = 1, we establish logarithmic growth. For the case $\backslash$beta {\textgreater} 1, we establish a connection with a class of inhomogeneous random graphs known as the Chung-Lu model. Assume that we use the Poincar$\backslash$'e disc representation of a hyperbolic space. If we condition on the distance of each one of the points from the origin, then the probability that two given points are adjacent is expressed through the kernel of this inhomogeneous random graph.},
archivePrefix = {arXiv},
arxivId = {1205.2923},
author = {Erd{\"{o}}s, Paul and R{\'{e}}nyi, Alfr{\'{e}}d},
doi = {10.2307/1999405},
eprint = {1205.2923},
isbn = {ISSN{\~{}}{\~{}}0020-1383},
issn = {00029947},
journal = {Publ. Math. Inst. Hung. Acad. Sci.},
pages = {17--61},
pmid = {1999405},
title = {{On the evolution of random graphs}},
url = {http://arxiv.org/abs/1205.2923},
volume = {5},
year = {1960}
}
@article{CRT05,
author = {Candes, Emmanuel and Romberg, Justin and Tao, Terence},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Candes, Romberg, Tao - 2005 - Stable signal recovery from incomplete and inaccurate measurements.pdf:pdf},
journal = {Comm. Pure Appl. Math},
pages = {1207--1223},
title = {{Stable signal recovery from incomplete and inaccurate measurements}},
volume = {59},
year = {2005}
}
@article{Chandrasekaran2010,
abstract = {Suppose we have samples of a $\backslash$emph{\{}subset{\}} of a collection of random variables. No additional information is provided about the number of latent variables, nor of the relationship between the latent and observed variables. Is it possible to discover the number of hidden components, and to learn a statistical model over the entire collection of variables? We address this question in the setting in which the latent and observed variables are jointly Gaussian, with the conditional statistics of the observed variables conditioned on the latent variables being specified by a graphical model. As a first step we give natural conditions under which such latent-variable Gaussian graphical models are identifiable given marginal statistics of only the observed variables. Essentially these conditions require that the conditional graphical model among the observed variables is sparse, while the effect of the latent variables is ``spread out'' over most of the observed variables. Next we propose a tractable convex program based on regularized maximum-likelihood for model selection in this latent-variable setting; the regularizer uses both the {\$}\backslashell{\_}1{\$} norm and the nuclear norm. Our modeling framework can be viewed as a combination of dimensionality reduction (to identify latent variables) and graphical modeling (to capture remaining statistical structure not attributable to the latent variables), and it consistently estimates both the number of hidden components and the conditional graphical model structure among the observed variables. These results are applicable in the high-dimensional setting in which the number of latent/observed variables grows with the number of samples of the observed variables. The geometric properties of the algebraic varieties of sparse matrices and of low-rank matrices play an important role in our analysis.},
archivePrefix = {arXiv},
arxivId = {1008.1290},
author = {Chandrasekaran, Venkat and Parrilo, Pablo a. and Willsky, Alan S.},
doi = {10.1214/11-AOS949},
eprint = {1008.1290},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chandrasekaran, Parrilo, Willsky - 2010 - Latent Variable Graphical Model Selection via Convex Optimization.pdf:pdf;:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chandrasekaran, Parrilo, Willsky - 2012 - Latent variable graphical model selection via convex optimization.pdf:pdf},
issn = {0090-5364},
journal = {Communication, Control, and Computing (Allerton), 2010 48th Annual Allerton Conference on},
keywords = {62F12,62H12,Gaussian graphical models,Optimization and Control,Statistics,Theory,ables,algebraic statistics,and phrases,covarianc,covariance selection,gaussian graphical models,high-dimensional asymptotics,latent vari-,low-rank,regularization,sparsity},
month = {aug},
number = {4},
pages = {1610--1613},
title = {{Latent Variable Graphical Model Selection via Convex Optimization}},
url = {http://projecteuclid.org/euclid.aos/1351602527 http://arxiv.org/abs/1008.1290},
volume = {40},
year = {2010}
}
@article{Chun2003,
abstract = {ABSTRACT PlanetLab is a global overlay network for developing and ac- cessing broad-coverage network services. Our goal is to grow to 1000 geographically distributed nodes, connected by a di- verse collection of links. PlanetLab allows multiple services to run concurrently and ...},
author = {Chun, Brent and Culler, David and Roscoe, Timothy and Bavier, Andy and Peterson, Larry and Wawrzoniak, Mike and Bowman, Mic},
doi = {10.1145/956993.956995},
issn = {01464833},
journal = {ACM SIGCOMM Computer Communication Review},
number = {3},
pages = {3},
title = {{PlanetLab}},
url = {http://portal.acm.org/citation.cfm?doid=956993.956995},
volume = {33},
year = {2003}
}
@article{Xu2010,
author = {Xu, H and Caramanis, C},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu, Caramanis, Sanghavi - 2010 - Robust PCA via Outlier Pursuit.pdf:pdf},
journal = {Information Theory, IEEE},
keywords = {boundary value problems,connecting orbits,invariant manifolds,numerical continuation,restricted three body problem},
pages = {1--22},
title = {{Robust PCA via outlier pursuit}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=6126034},
year = {2010}
}
@article{Collins2001,
author = {Collins, Michael and Dasgupta, S and Schapire, RE},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Collins, Dasgupta, Schapire - 2001 - A Generalization of Principal Component Analysis to the Exponential Family.pdf:pdf},
journal = {Proceedings of NIPS},
number = {1},
title = {{A Generalization of Principal Component Analysis to the Exponential Family}},
url = {http://www-2.cs.cmu.edu/Groups/NIPS/NIPS2001/papers/psgz/AA27.ps.gz},
year = {2001}
}
@article{Jin2008,
abstract = {One key function of intelligent transportation systems is to automatically detect abnormal traffic phenomena and to help further investigations of the cause of the abnormality. This paper describes a robust principal components analysis (RPCA)-based abnormal traffic flow pattern isolation and loop detector fault detection method. The results show that RPCA is a useful tool to distinguish regular traffic flow from abnormal traffic flow patterns caused by accidents and loop detector faults. This approach gives an effective traffic flow data pre-processing method to reduce the human effort in finding potential loop detector faults. The method can also be used to further investigate the causes of the abnormality. ?? 2008 Tsinghua University Press.},
author = {Jin, Xuexiang and Zhang, Yi and Li, Li and Hu, Jianming},
doi = {10.1016/S1007-0214(08)72208-9},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin et al. - 2008 - Robust PCA-Based Abnormal Traffic Flow Pattern Isolation and Loop Detector Fault Detection.pdf:pdf},
issn = {10070214},
journal = {Tsinghua Science and Technology},
keywords = {loop detector faults,robust principal components analysis (RPCA),traffic flow pattern},
number = {6},
pages = {829--835},
title = {{Robust PCA-Based Abnormal Traffic Flow Pattern Isolation and Loop Detector Fault Detection}},
volume = {13},
year = {2008}
}
@article{Pascoal2012,
abstract = {Robust statistics is a branch of statistics which includes statistical methods capable of dealing adequately with the presence of outliers. In this paper, we propose an anomaly detection method that combines a feature selection algorithm and an outlier detection method, which makes extensive use of robust statistics. Feature selection is based on a mutual information metric for which we have developed a robust estimator; it also includes a novel and automatic procedure for determining the number of relevant features. Outlier detection is based on robust Principal Component Analysis (PCA) which, opposite to classical PCA, is not sensitive to outliers and precludes the necessity of training using a reliably labeled dataset, a strong advantage from the operational point of view. To evaluate our method we designed a network scenario capable of producing a perfect ground-truth under real (but controlled) traffic conditions. Results show the significant improvements of our method over the corresponding classical ones. Moreover, despite being a largely overlooked issue in the context of anomaly detection, feature selection is found to be an important preprocessing step, allowing adaption to different network conditions and inducing significant performance gains.},
author = {Pascoal, Cla{\'{u}}dia and {De Oliveira}, M. Ros{\'{a}}rio and Valadas, Rui and Filzmoser, Peter and Salvador, Paulo and Pacheco, Ant{\'{o}}nio},
doi = {10.1109/INFCOM.2012.6195548},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pascoal et al. - 2012 - Robust feature selection and robust PCA for internet traffic anomaly detection.pdf:pdf},
isbn = {9781467307758},
issn = {0743166X},
journal = {Proceedings - IEEE INFOCOM},
pages = {1755--1763},
title = {{Robust feature selection and robust PCA for internet traffic anomaly detection}},
year = {2012}
}
@article{Paffenroth2013a,
author = {Paffenroth, R. and Nong, R. and Toit, P. Du},
journal = {in preparation},
title = {{Fast Alternating Direction Method of Multipliers Solvers for Robust Principal Component Analysis and Big Data}},
year = {2013}
}
@misc{geohot,
annote = {undefined},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Geohot.html:html},
title = {{Geohot}},
url = {http://www.theinquirer.net/inquirer/news/2046627/sony-hacker-denies-playstation-network-exploit},
urldate = {2011-06-21}
}
@article{Shlens2009,
abstract = {Principal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as well as the when, the how and the why of applying this technique.},
archivePrefix = {arXiv},
arxivId = {1404.1100},
author = {Shlens, Jonathon},
doi = {10.1.1.115.3503},
eprint = {1404.1100},
isbn = {9781457705052},
journal = {Tutorial, Salk Institute},
keywords = {Statistics},
pages = {1--12},
pmid = {2406666115306510087},
title = {{A Tutorial on Principal Component Analysis}},
url = {papers3://publication/uuid/3171422B-A890-406E-9DF1-F0D13475D1F5},
year = {2009}
}
@article{Cand,
author = {Cand, Emmanuel J and Wakin, Michael B},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cand, Wakin - Unknown - “ People Hearing Without Listening ” An Introduction To Compressive Sampling.pdf:pdf},
title = {{“ People Hearing Without Listening :” An Introduction To Compressive Sampling}}
}
@book{Aggarwal2012,
abstract = {The biomedical community makes extensive use of text mining technology. In the past several years, enormous progress has been made in developing tools and methods, and the community has been witness to some exciting developments. Although the state of the community is regularly reviewed, the sheer volume of work related to biomedical text mining and the rapid pace in which progress continues to be made make this a worthwhile, if not necessary, endeavor. This chapter provides a brief overview of the current state of text mining in the biomedical domain. Emphasis is placed on the resources and tools available to biomedical researchers and practitioners, as well as the major text mining tasks of interest to the community. These tasks include the recognition of explicit facts from biomedical literature, the discovery of previously unknown or implicit facts, document summarization, and question answering. For each topic, its basic challenges and methods are outlined and recent and influential work is reviewed.},
author = {Aggarwal, CC and Zhai, CX},
booktitle = {Mining Text Data},
doi = {10.1007/978-1-4614-3223-4},
isbn = {978-1-4614-3223-4},
issn = {20403372},
pages = {889--903},
pmid = {22499159},
title = {{Mining text data}},
url = {http://www.springerlink.com/index/10.1007/978-1-4614-3223-4{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=vFHOx8wfSU0C{\&}oi=fnd{\&}pg=PR5{\&}dq=Mining+Text+Data{\&}ots=oaadUEiCTx{\&}sig=WWPHKZpR-2ehG{\_}cnB72GdOPemVk{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=vFHOx8wfSU0C{\&}oi=fnd{\&}pg=PR5{\&}dq=Mining+text+data{\&}ots=oaad{\_}CjBVu{\&}sig=tjji7ofrXPYF1-{\_}hXVcssENLu1U{\%}5Cnhttp://books.google.com/books?hl=en{\&}lr={\&}id=vFHOx8wfSU0C{\&}oi=fnd{\&}pg=PR5{\&}dq=Mining+text+data{\&}ots=oaahWGiCYy{\&}sig={\_}13biylE8RUDv6ma0M9OBpsejZQ},
volume = {4},
year = {2012}
}
@misc{Cea1999,
abstract = {The goal of this paper is to present and compare several compression methods (fractal, wavelets, JPEG, ...) applied on astronomical images. Quality is estimated from visual aspect, and also from photometry and astrometric measurements. Computation time of each method is discussed. 1 Introduction  Image compression can be necessitated for different reasons, which may in practice motivate different compression strategies. Cases which can be easily distinguished include: quicklook (e.g. from the Hubble Space Telescope image archive [8]); very large images (e.g. the all-sky atlas, ALADIN, with links to cataloged information on tens of millions of astronomical objects [1]); fast access to large pictorial databases; and Web-based and other types of data transmission (a number of references to past work on progressive image transmission can be found in [7]). Methods used in astronomy are HCOMPRESS[18], FITSPRESS [14], and JPEG[6]. Two other methods have also been proposed for astronomical ima...},
author = {Cea, Starck and Starck, J. -l. and Gif, F- and Cedex, Yvette and Murtagh, F. and Louys, M.},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cea et al. - 1999 - Astronomical Image Compression.pdf:pdf},
pages = {579--590},
publisher = {Astronomy and Astrophysics, Suppl. Ser},
title = {{Astronomical Image Compression}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.56.2948},
volume = {136},
year = {1999}
}
@article{Zhou,
archivePrefix = {arXiv},
arxivId = {arXiv:1001.2363v1},
author = {Zhou, Zihan and Li, Xiaodong and Wright, John and Cand, Emmanuel and Candes, Emmanuel and Ma, Yi},
doi = {10.1109/ISIT.2010.5513535},
eprint = {arXiv:1001.2363v1},
isbn = {978-1-4244-7892-7},
journal = {Main},
keywords = {Asia,Computer errors,Data engineering,Data mining,Error analysis,Mathematics,Noise level,Noise robustness,Principal component analysis,Sparse matrices,convex program,convex programming,data matrix,gross sparse errors,stable principal component pursuit},
language = {English},
month = {jun},
pages = {1518--1522},
publisher = {IEEE},
title = {{Stable Principal Component Pursuit}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5513535},
year = {2010}
}
@article{Krishnamurthy,
author = {Krishnamurthy, Akshay},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Krishnamurthy - Unknown - Robust Multi-Source Network Tomography using Selective Probes.pdf:pdf},
journal = {Machine Learning},
title = {{Robust Multi-Source Network Tomography using Selective Probes}}
}
@book{Knuth2014,
author = {Knuth, DE},
title = {{Art of Computer Programming, Volume 2: Seminumerical Algorithms, The}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=Zu-HAwAAQBAJ{\&}oi=fnd{\&}pg=PP17{\&}dq=the+art+of+computer+programming+seminumerical{\&}ots=9mcdXnVx7T{\&}sig=jl4l2wdZ{\_}ttYQEEscdXMJjWewsY},
year = {2014}
}
@misc{snortids,
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Snort Home Page.html:html},
howpublished = {http://www.snort.org/},
title = {{Snort :: Home Page}},
url = {http://www.snort.org/},
urldate = {2013-07-10}
}
@article{Tosic2011,
author = {Tosic, I and Frossard, P},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Tosic, Frossard - 2011 - Dictionary learning.pdf:pdf},
journal = {Signal Processing Magazine, IEEE},
title = {{Dictionary learning}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5714407},
year = {2011}
}
@misc{Starck2002,
abstract = {We outline digital implementations of two newly developed multiscale representation systems, namely, the ridgelet and curvelet transforms. We apply these digital transforms to the problem of restoring an image from noisy data and compare our results with those obtained via well established methods based on the thresholding of wavelet coefficients. We show that the curvelet transform allows us also to well enhance elongated features contained in the data. Finally, we describe the Morphological Component Analysis, which consists in separating features in an image which do not present the same morphological characteristics. A range of examples illustrates the results.},
author = {Starck, J.L. and Donoho, D.L. and Candes, E.J.},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Starck, Donoho, Candes - 2002 - Astronomical Image Representation by the Curvelet Transform.pdf:pdf},
title = {{Astronomical Image Representation by the Curvelet Transform}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.15.3709},
year = {2002}
}
@techreport{lin2009a,
author = {Lin, Z and Chen, M and Wu, L and Ma, Y},
institution = {UIUC},
month = {nov},
number = {ENG-09-2215},
title = {{FIXME: The Augmented Lagrange Multiplier Method for Exact Recovery of Corrupted Low-Rank Matrices}},
year = {2009}
}
@article{Cerqueti2012,
author = {Cerqueti, Roy and Costantini, Mauro and Lupi, Claudio},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Cerqueti, Costantini, Lupi - 2012 - A copula-based analysis of false discovery rate control under dependence assumptions.pdf:pdf},
keywords = {copulas,false discovery rate,multiple testing},
number = {065},
title = {{A copula-based analysis of false discovery rate control under dependence assumptions}},
url = {http://road.unimol.it/handle/2192/168},
year = {2012}
}
@article{Shlens2009a,
abstract = {Principal component analysis (PCA) is a mainstay of modern data analysis - a black box that is widely used but (sometimes) poorly understood. The goal of this paper is to dispel the magic behind this black box. This manuscript focuses on building a solid intuition for how and why principal component analysis works. This manuscript crystallizes this knowledge by deriving from simple intuitions, the mathematics behind PCA. This tutorial does not shy away from explaining the ideas informally, nor does it shy away from the mathematics. The hope is that by addressing both aspects, readers of all levels will be able to gain a better understanding of PCA as well as the when, the how and the why of applying this technique.},
archivePrefix = {arXiv},
arxivId = {1404.1100},
author = {Shlens, Jonathon},
doi = {10.1.1.115.3503},
eprint = {1404.1100},
isbn = {9781457705052},
journal = {Tutorial, Salk Institute},
keywords = {Statistics},
pages = {1--12},
pmid = {2406666115306510087},
title = {{A Tutorial on Principal Component Analysis}},
url = {papers3://publication/uuid/3171422B-A890-406E-9DF1-F0D13475D1F5},
year = {2009}
}
@inproceedings{OhSchSas05,
abstract = {Multiple-target tracking is a canonical application of sensor networks
as it exhibits different aspects of sensor networks such as event
detection, sensor information fusion, multi-hop communication, sensor
management and decision making. The task of tracking multiple objects
in a sensor network is challenging due to constraints on a sensor
node such as short communication and sensing ranges, a limited amount
of memory and limited computational power. In addition, since a sensor
network surveillance system needs to operate autonomously without
human operators, it requires an autonomous tracking algorithm which
can track an unknown number of targets. In this paper, we develop
a scalable hierarchical multiple-target tracking algorithm that is
autonomous and robust against transmission failures, communication
delays and sensor localization error.},
address = {Barcelona, Spain},
author = {Oh, Songhwai and Schenato, Luca and Sastry, Shankar},
booktitle = {International Conference on Robotics and Automation (ICRA)},
month = {apr},
title = {{A Hierarchical Multiple-Target Tracking Algorithm for Sensor Networks}},
url = {http://www.eecs.berkeley.edu/{~}sho/research.html},
year = {2005}
}
@phdthesis{Robinson06,
address = {Wright-Patterson Air Force Base, OH},
annote = {AFIT/GAE/ENY/06-J14},
author = {Robinson, B K},
month = {jun},
school = {Air Force Institute of Technology},
title = {{An investigation into robust wind correction algorithms for off-the-shelf unmanned aerial vehicle autopilots}},
type = {Master's Thesis},
year = {2006}
}
@inproceedings{Kunegis2013,
abstract = {This is the Handbook of Network Analysis, the companion article to the KONECT (Koblenz Network Collection) project. This project is intended to collect network datasets, analyse them systematically, and provide both datasets and the underlying network analysis code to researchers. This article outlines the project, gives all definitions used within the project, reviews all network statistics used, reviews all network plots used, and gives a brief overview of the API used by KONECT.},
archivePrefix = {arXiv},
arxivId = {1402.5500},
author = {Kunegis, J{\'{e}}r{\^{o}}me},
booktitle = {Proceedings of the 22Nd International Conference on World Wide Web Companion},
eprint = {1402.5500},
isbn = {978-1-4503-2038-2},
keywords = {network analysis,web observatory},
pages = {1343--1350},
title = {{The Koblenz Network Collection}},
url = {http://dl.acm.org/citation.cfm?id=2487788.2488173},
year = {2013}
}
@article{Lobo1998,
author = {Lobo, M},
doi = {10.1016/S0024-3795(98)10032-0},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lobo - 1998 - Applications of second-order cone programming.pdf:pdf},
issn = {00243795},
journal = {Linear Algebra and its Applications},
month = {nov},
number = {1-3},
pages = {193--228},
title = {{Applications of second-order cone programming}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0024379598100320},
volume = {284},
year = {1998}
}
@article{Coifman2006a,
abstract = {In this paper, we provide a framework based upon diffusion processes for finding meaningful geometric descriptions of data sets. We show that eigenfunctions of Markov matrices can be used to construct coordinates called diffusion maps that generate efficient representations of complex geometric structures. The associated family of diffusion distances, obtained by iterating the Markov matrix, defines multiscale geometries that prove to be useful in the context of data parametrization and dimensionality reduction. The proposed framework relates the spectral properties of Markov processes to their geometric counterparts and it unifies ideas arising in a variety of contexts such as machine learning, spectral graph theory and eigenmap methods.},
author = {Coifman, R and Lafon, S},
doi = {10.1016/j.acha.2006.04.006},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Coifman, Lafon - 2006 - Diffusion maps.pdf:pdf},
institution = {Princeton University},
issn = {10635203},
journal = {Applied and Computational Harmonic Analysis},
keywords = {diffusion metric,diffusion processes,dimensionality reduction,eigenmaps,graph laplacian,manifold learning},
number = {1},
pages = {5--30},
publisher = {Elsevier},
title = {{Diffusion maps}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S1063520306000546},
volume = {21},
year = {2006}
}
@book{Myerson1997,
author = {Myerson, Roger B.},
isbn = {0674341163},
pages = {600},
publisher = {Harvard University Press},
title = {{Game Theory: Analysis of Conflict}},
url = {http://www.amazon.com/Game-Theory-Analysis-Roger-Myerson/dp/0674341163},
year = {1997}
}
@article{Chandrasekaran2009,
archivePrefix = {arXiv},
arxivId = {0906.2220},
author = {Chandrasekaran, Venkat and Sanghavi, Sujay and Parrilo, Pablo A. and Willsky, Alan S.},
eprint = {0906.2220},
journal = {arXiv:0906.2220v1},
month = {jun},
title = {{Rank-Sparsity Incoherence for Matrix Decomposition}},
url = {http://arxiv.org/abs/0906.2220},
year = {2009}
}
@article{McAuley2008,
abstract = {A recent paper [1] proposed a provably optimal polynomial time method for performing near-isometric point pattern matching by means of exact probabilistic inference in a chordal graphical model. Its fundamental result is that the chordal graph in question is shown to be globally rigid, implying that exact inference provides the same matching solution as exact inference in a complete graphical model. This implies that the algorithm is optimal when there is no noise in the point patterns. In this paper, we present a new graph that is also globally rigid but has an advantage over the graph proposed in [1]: Its maximal clique size is smaller, rendering inference significantly more efficient. However, this graph is not chordal, and thus, standard Junction Tree algorithms cannot be directly applied. Nevertheless, we show that loopy belief propagation in such a graph converges to the optimal solution. This allows us to retain the optimality guarantee in the noiseless case, while substantially reducing both memory requirements and processing time. Our experimental results show that the accuracy of the proposed solution is indistinguishable from that in [1] when there is noise in the point patterns.},
archivePrefix = {arXiv},
arxivId = {0710.0043},
author = {McAuley, Julian J. and Caetano, Tib{\'{e}};rio S. and Barbosa, Marconi S.},
doi = {10.1109/TPAMI.2008.124},
eprint = {0710.0043},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {Belief propagation,Chordal graphs,Global rigidity,Graph matching,Graphical models,Point pattern matching},
pages = {2047--2054},
pmid = {18787251},
title = {{Graph rigidity, cyclic belief propagation, and point pattern matching}},
volume = {30},
year = {2008}
}
@article{Li00,
author = {Li, R},
journal = {IEEE Transactions on Aerospace and Electronic Systems},
pages = {266--278},
title = {{Numerically robust implementation of multiple-model algorithms}},
volume = {$\backslash$bf 36},
year = {2000}
}
@article{Mardani2012,
abstract = {In the backbone of large-scale networks, origin-to-destination (OD) traffic flows experience abrupt unusual changes known as traffic volume anomalies, which can result in congestion and limit the extent to which end-user quality of service requirements are met. As a means of maintaining seamless end-user experience in dynamic environments, as well as for ensuring network security, this paper deals with a crucial network monitoring task termed dynamic anomalography. Given link traffic measurements (noisy superpositions of unobserved OD flows) periodically acquired by backbone routers, the goal is to construct an estimated map of anomalies in real time, and thus summarize the network `health state' along both the flow and time dimensions. Leveraging the low intrinsic-dimensionality of OD flows and the sparse nature of anomalies, a novel online estimator is proposed based on an exponentially-weighted least-squares criterion regularized with the sparsity-promoting l1-norm of the anomalies, and the nuclear norm of the nominal traffic matrix. After recasting the non-separable nuclear norm into a form amenable to online optimization, a real-time algorithm for dynamic anomalography is developed and its convergence established under simplifying technical assumptions. For operational conditions where computational complexity reductions are at a premium, a lightweight stochastic gradient algorithm based on Nesterov's acceleration technique is developed as well. Comprehensive numerical tests with both synthetic and real network data corroborate the effectiveness of the proposed online algorithms and their tracking capabilities, and demonstrate that they outperform state-of-the-art approaches developed to diagnose traffic anomalies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1208.4043v1},
author = {Mardani, Morteza and Mateos, Gonzalo and Giannakis, Georgios B.},
doi = {10.1109/JSTSP.2012.2233193},
eprint = {arXiv:1208.4043v1},
isbn = {1932-4553},
issn = {19324553},
journal = {IEEE Journal on Selected Topics in Signal Processing},
keywords = {Traffic volume anomalies,low rank,network cartography,online optimization,sparsity},
month = {aug},
number = {1},
pages = {50--66},
title = {{Dynamic anomalography: Tracking network anomalies via sparsity and low rank}},
url = {http://arxiv.org/abs/1208.4043 http://dx.doi.org/10.1109/JSTSP.2012.2233193},
volume = {7},
year = {2013}
}
@misc{dpip,
author = {Db-ip database, The},
title = {https://db-ip.com},
year = {2015}
}
@book{statsnutshell,
author = {Parker, Bret H.},
booktitle = {Journal of the American Society for Information Science},
doi = {10.1002/(SICI)1097-4571(199709)48:9<861::AID-ASI11>3.0.CO;2-U},
isbn = {978-1-4493-1692-1},
issn = {0002-8231},
month = {nov},
number = {9},
pages = {861--862},
publisher = {Elsevier Science},
series = {The Morgan Kaufmann Series in Networking},
title = {{Computer networks: A systems approach}},
url = {http://doi.wiley.com/10.1002/(SICI)1097-4571(199709)48:9{\%}3C861::AID-ASI11{\%}3E3.0.CO;2-U},
volume = {48},
year = {1997}
}
@article{Asif2010a,
author = {Asif, M Salman},
file = {:home/rcpaffenroth/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Asif - 2010 - Dynamic Updating for L1 Minimization.pdf:pdf},
journal = {Selected Topics in Signal},
number = {2},
pages = {421--434},
title = {{Dynamic Updating for L1 Minimization}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=5419067},
volume = {4},
year = {2010}
}
